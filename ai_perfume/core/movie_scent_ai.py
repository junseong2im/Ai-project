#!/usr/bin/env python3
"""
ì˜í™” ì¥ë©´ìš© ê³ ê¸‰ ëƒ„ìƒˆ êµ¬ì¡° ë”¥ëŸ¬ë‹ AI ì‹œìŠ¤í…œ
í•œê³„ì¹˜ê¹Œì§€ í•™ìŠµëœ ë‹¤ì°¨ì› í–¥ìˆ˜ ì¶”ì²œ ì—”ì§„
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
import json
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import logging
import time
from sklearn.preprocessing import StandardScaler, LabelEncoder, MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
import random
from collections import defaultdict
import pickle

logger = logging.getLogger(__name__)

class MovieScentDataset(Dataset):
    """ì˜í™” ì¥ë©´-í–¥ìˆ˜ ë°ì´í„°ì…‹"""
    
    def __init__(self, features: np.ndarray, targets: np.ndarray, metadata: Optional[np.ndarray] = None):
        self.features = torch.FloatTensor(features)
        self.targets = torch.FloatTensor(targets)
        self.metadata = torch.FloatTensor(metadata) if metadata is not None else None
    
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        if self.metadata is not None:
            return self.features[idx], self.targets[idx], self.metadata[idx]
        return self.features[idx], self.targets[idx]

class AdvancedMovieNeuralNetwork(nn.Module):
    """ì˜í™” ì¥ë©´ ë¶„ì„ìš© ê³ ê¸‰ ì‹ ê²½ë§
    
    ë‹¤ì¤‘ í—¤ë“œ ì–´í…ì…˜, ì”ì°¨ ì—°ê²°, ë°°ì¹˜ ì •ê·œí™”ë¥¼ í¬í•¨í•œ ìµœì‹  ì•„í‚¤í…ì²˜
    """
    
    def __init__(
        self,
        input_dim: int,
        hidden_dims: List[int],
        output_dim: int,
        num_heads: int = 8,
        dropout_rate: float = 0.3,
        use_attention: bool = True,
        use_residual: bool = True
    ):
        super(AdvancedMovieNeuralNetwork, self).__init__()
        
        self.use_attention = use_attention
        self.use_residual = use_residual
        
        # ì…ë ¥ ì„ë² ë”© ì¸µ
        self.input_embedding = nn.Linear(input_dim, hidden_dims[0])
        
        # ë‹¤ì¤‘ í—¤ë“œ ì–´í…ì…˜ (ì„ íƒì‚¬í•­)
        if use_attention:
            self.attention = nn.MultiheadAttention(
                embed_dim=hidden_dims[0],
                num_heads=num_heads,
                dropout=dropout_rate,
                batch_first=True
            )
            self.attention_norm = nn.LayerNorm(hidden_dims[0])
        
        # í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬
        self.layers = nn.ModuleList()
        prev_dim = hidden_dims[0]
        
        for hidden_dim in hidden_dims[1:]:
            self.layers.append(nn.Sequential(
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.BatchNorm1d(hidden_dim),
                nn.Dropout(dropout_rate)
            ))
            prev_dim = hidden_dim
        
        # ì¶œë ¥ ì¸µë“¤
        self.intensity_head = nn.Linear(prev_dim, 1)  # í–¥ìˆ˜ ê°•ë„
        self.scent_profile_head = nn.Linear(prev_dim, output_dim - 1)  # í–¥ìˆ˜ í”„ë¡œí•„
        
        # ì”ì°¨ ì—°ê²°ì„ ìœ„í•œ í”„ë¡œì ì…˜ ì¸µë“¤
        if use_residual:
            self.residual_projections = nn.ModuleList()
            for i, hidden_dim in enumerate(hidden_dims[1:]):
                if i == 0:
                    self.residual_projections.append(nn.Linear(hidden_dims[0], hidden_dim))
                else:
                    self.residual_projections.append(nn.Linear(hidden_dims[i], hidden_dim))
    
    def forward(self, x):
        # ì…ë ¥ ì„ë² ë”©
        x = self.input_embedding(x)
        
        # ë‹¤ì¤‘ í—¤ë“œ ì–´í…ì…˜
        if self.use_attention:
            # ë°°ì¹˜ ì°¨ì› í™•ì¥ (ì‹œí€€ìŠ¤ ê¸¸ì´ 1)
            x_seq = x.unsqueeze(1)
            attn_out, _ = self.attention(x_seq, x_seq, x_seq)
            x = self.attention_norm(x + attn_out.squeeze(1))
        
        # í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ (ì”ì°¨ ì—°ê²° í¬í•¨)
        for i, layer in enumerate(self.layers):
            residual = x
            x = layer(x)
            
            # ì”ì°¨ ì—°ê²°
            if self.use_residual and i < len(self.residual_projections):
                residual_projected = self.residual_projections[i](residual)
                x = x + residual_projected
        
        # ì¶œë ¥ í—¤ë“œë“¤
        intensity = torch.sigmoid(self.intensity_head(x)) * 10  # 0-10 ìŠ¤ì¼€ì¼
        scent_profile = torch.sigmoid(self.scent_profile_head(x))
        
        return torch.cat([intensity, scent_profile], dim=1)

class MovieScentProcessor:
    """ì˜í™” ì¥ë©´-í–¥ìˆ˜ ë°ì´í„° ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.movie_data = None
        self.scent_vectorizer = TfidfVectorizer(max_features=500)
        self.emotion_vectorizer = TfidfVectorizer(max_features=200)
        self.visual_vectorizer = TfidfVectorizer(max_features=300)
        self.scalers = {}
        self.encoders = {}
        
        # í–¥ìˆ˜ ë…¸íŠ¸ ì¹´í…Œê³ ë¦¬ (í™•ì¥ëœ ë²„ì „)
        self.scent_categories = {
            'citrus': ['bergamot', 'lemon', 'orange', 'grapefruit', 'lime', 'mandarin', 'citron'],
            'floral': ['rose', 'jasmine', 'lily', 'violet', 'tuberose', 'magnolia', 'peony', 'iris'],
            'woody': ['cedar', 'sandalwood', 'pine', 'cypress', 'oak', 'birch', 'bamboo'],
            'oriental': ['amber', 'vanilla', 'musk', 'oud', 'incense', 'benzoin', 'myrrh'],
            'fresh': ['mint', 'eucalyptus', 'sea breeze', 'ozone', 'green leaves', 'cucumber'],
            'spicy': ['cinnamon', 'nutmeg', 'cardamom', 'black pepper', 'clove', 'ginger'],
            'fruity': ['apple', 'peach', 'berry', 'plum', 'apricot', 'pear', 'cherry'],
            'gourmand': ['chocolate', 'coffee', 'caramel', 'honey', 'almond', 'coconut', 'praline'],
            'animalic': ['leather', 'musk', 'ambergris', 'civet', 'castoreum'],
            'herbal': ['basil', 'rosemary', 'thyme', 'sage', 'lavender', 'chamomile'],
            'aquatic': ['ocean', 'rain', 'water lily', 'sea salt', 'marine'],
            'metallic': ['steel', 'iron', 'copper', 'metallic', 'mineral'],
            'smoky': ['smoke', 'tobacco', 'birch tar', 'burnt wood', 'fire'],
            'earthy': ['soil', 'moss', 'mushroom', 'wet earth', 'clay', 'stone'],
            'synthetic': ['aldehydes', 'synthetic', 'chemical', 'laboratory', 'artificial']
        }
        
        logger.info("ì˜í™” í–¥ìˆ˜ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_movie_data(self, data_path: str) -> Dict:
        """ì˜í™” ë°ì´í„° ë¡œë“œ"""
        try:
            with open(data_path, 'r', encoding='utf-8') as f:
                self.movie_data = json.load(f)
            logger.info(f"ì˜í™” ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.movie_data['movie_scenes'])}ê°œ ì¥ë©´")
            return self.movie_data
        except Exception as e:
            logger.error(f"ì˜í™” ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def expand_dataset(self, base_scenes: List[Dict], multiplier: int = 50) -> List[Dict]:
        """ë°ì´í„°ì…‹ í™•ì¥ì„ í†µí•œ ë‹¤ì–‘ì„± ì¦ëŒ€"""
        expanded_scenes = []
        
        # ê¸°ë³¸ ì¥ë©´ë“¤ ì¶”ê°€
        expanded_scenes.extend(base_scenes)
        
        # ë³€í˜•ëœ ì¥ë©´ë“¤ ìƒì„±
        for _ in range(multiplier):
            for base_scene in base_scenes:
                # ì¥ë©´ ë³€í˜•
                new_scene = self._create_scene_variation(base_scene)
                expanded_scenes.append(new_scene)
        
        logger.info(f"ë°ì´í„°ì…‹ í™•ì¥ ì™„ë£Œ: {len(expanded_scenes)}ê°œ ì¥ë©´")
        return expanded_scenes
    
    def _create_scene_variation(self, base_scene: Dict) -> Dict:
        """ê¸°ë³¸ ì¥ë©´ì˜ ë³€í˜• ìƒì„±"""
        variation = base_scene.copy()
        variation['scene_id'] = f"{base_scene['scene_id']}_var_{random.randint(1000, 9999)}"
        
        # ì‹œê°„ëŒ€ ë³€í˜•
        times = ['dawn', 'morning', 'afternoon', 'evening', 'night', 'midnight']
        variation['time_of_day'] = random.choice(times)
        
        # ë‚ ì”¨ ë³€í˜•
        weathers = ['sunny', 'cloudy', 'rainy', 'snowy', 'foggy', 'windy', 'stormy']
        variation['weather'] = random.choice(weathers)
        
        # ê°ì • ë³€í˜• (ê¸°ë³¸ ê°ì •ì— ì¶”ê°€)
        additional_emotions = ['melancholy', 'excitement', 'serenity', 'tension', 'euphoria']
        if random.random() < 0.3:
            variation['emotions'].append(random.choice(additional_emotions))
        
        # í–¥ìˆ˜ í”„ë¡œí•„ ë³€í˜•
        self._modify_scent_profile(variation['scent_profile'])
        
        return variation
    
    def _modify_scent_profile(self, scent_profile: Dict):
        """í–¥ìˆ˜ í”„ë¡œí•„ ìˆ˜ì •"""
        # ê°•ë„ ë³€í˜• (Â±2 ë²”ìœ„)
        scent_profile['intensity'] = max(1, min(10, 
            scent_profile['intensity'] + random.randint(-2, 2)))
        
        # ì§€ì†ì„± ë³€í˜• (Â±1 ë²”ìœ„)
        scent_profile['longevity'] = max(1, min(10,
            scent_profile['longevity'] + random.randint(-1, 1)))
        
        # íˆ¬ì‚¬ë ¥ ë³€í˜• (Â±1 ë²”ìœ„)
        scent_profile['projection'] = max(1, min(10,
            scent_profile['projection'] + random.randint(-1, 1)))
        
        # ë…¸íŠ¸ ë³€í˜• (30% í™•ë¥ ë¡œ ë…¸íŠ¸ ì¶”ê°€/ì œê±°)
        if random.random() < 0.3:
            # ëœë¤ ì¹´í…Œê³ ë¦¬ì—ì„œ ë…¸íŠ¸ ì¶”ê°€
            category = random.choice(list(self.scent_categories.keys()))
            note = random.choice(self.scent_categories[category])
            
            note_type = random.choice(['primary_notes', 'secondary_notes'])
            if note not in scent_profile[note_type]:
                scent_profile[note_type].append(note)
    
    def extract_features(self, scenes: List[Dict]) -> Tuple[np.ndarray, np.ndarray, Dict]:
        """ê³ ì°¨ì› íŠ¹ì„± ì¶”ì¶œ"""
        logger.info("ê³ ì°¨ì› íŠ¹ì„± ì¶”ì¶œ ì‹œì‘...")
        
        # ê¸°ë³¸ íŠ¹ì„±ë“¤
        scene_types = [scene['scene_type'] for scene in scenes]
        locations = [scene['location'] for scene in scenes]
        times = [scene['time_of_day'] for scene in scenes]
        weathers = [scene['weather'] for scene in scenes]
        
        # í…ìŠ¤íŠ¸ íŠ¹ì„±ë“¤
        emotions_text = [' '.join(scene['emotions']) for scene in scenes]
        visuals_text = [' '.join(scene['visual_elements']) for scene in scenes]
        scent_notes_text = [' '.join(scene['scent_profile']['primary_notes'] + 
                                   scene['scent_profile']['secondary_notes']) for scene in scenes]
        
        # ë²¡í„°í™”
        emotions_features = self.emotion_vectorizer.fit_transform(emotions_text).toarray()
        visuals_features = self.visual_vectorizer.fit_transform(visuals_text).toarray()
        scent_features = self.scent_vectorizer.fit_transform(scent_notes_text).toarray()
        
        # ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©
        scene_type_encoder = LabelEncoder()
        location_encoder = LabelEncoder()
        time_encoder = LabelEncoder()
        weather_encoder = LabelEncoder()
        mood_encoder = LabelEncoder()
        
        scene_type_encoded = scene_type_encoder.fit_transform(scene_types)
        location_encoded = location_encoder.fit_transform(locations)
        time_encoded = time_encoder.fit_transform(times)
        weather_encoded = weather_encoder.fit_transform(weathers)
        mood_encoded = mood_encoder.fit_transform([scene['scent_profile']['mood'] for scene in scenes])
        
        # ìˆ˜ì¹˜ íŠ¹ì„±ë“¤
        numerical_features = np.array([
            [
                scene['scent_profile']['intensity'],
                scene['scent_profile']['longevity'], 
                scene['scent_profile']['projection'],
                len(scene['emotions']),
                len(scene['visual_elements']),
                len(scene['scent_profile']['primary_notes']),
                len(scene['scent_profile']['secondary_notes'])
            ]
            for scene in scenes
        ])
        
        # í–¥ìˆ˜ ì¹´í…Œê³ ë¦¬ íŠ¹ì„±
        category_features = self._extract_scent_category_features(scenes)
        
        # ì‹œê°„-ë‚ ì”¨ ì¡°í•© íŠ¹ì„±
        temporal_features = self._extract_temporal_features(scenes)
        
        # ëª¨ë“  íŠ¹ì„± ê²°í•©
        all_features = np.concatenate([
            emotions_features,
            visuals_features,
            scene_type_encoded.reshape(-1, 1),
            location_encoded.reshape(-1, 1),
            time_encoded.reshape(-1, 1),
            weather_encoded.reshape(-1, 1),
            mood_encoded.reshape(-1, 1),
            numerical_features,
            category_features,
            temporal_features
        ], axis=1)
        
        # íƒ€ê²Ÿ ìƒì„± (í–¥ìˆ˜ í”„ë¡œí•„ ì˜ˆì¸¡)
        targets = np.array([
            [
                scene['scent_profile']['intensity'] / 10.0,  # ì •ê·œí™”
                scene['scent_profile']['longevity'] / 10.0,
                scene['scent_profile']['projection'] / 10.0,
            ] + self._encode_scent_notes(scene['scent_profile'])
            for scene in scenes
        ])
        
        # ì¸ì½”ë” ì €ì¥
        self.encoders = {
            'scene_type': scene_type_encoder,
            'location': location_encoder,
            'time': time_encoder,
            'weather': weather_encoder,
            'mood': mood_encoder
        }
        
        logger.info(f"íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ: {all_features.shape}, íƒ€ê²Ÿ: {targets.shape}")
        
        return all_features, targets, self.encoders
    
    def _extract_scent_category_features(self, scenes: List[Dict]) -> np.ndarray:
        """í–¥ìˆ˜ ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì„± ì¶”ì¶œ"""
        category_features = []
        
        for scene in scenes:
            all_notes = (scene['scent_profile']['primary_notes'] + 
                        scene['scent_profile']['secondary_notes'])
            
            # ê° ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°
            category_scores = []
            for category, notes in self.scent_categories.items():
                score = sum(1 for note in all_notes if any(n in note.lower() for n in notes))
                category_scores.append(score / max(1, len(all_notes)))  # ì •ê·œí™”
            
            category_features.append(category_scores)
        
        return np.array(category_features)
    
    def _extract_temporal_features(self, scenes: List[Dict]) -> np.ndarray:
        """ì‹œê°„-ë‚ ì”¨ ì¡°í•© íŠ¹ì„±"""
        temporal_features = []
        
        # ì‹œê°„ëŒ€ë³„ ê°€ì¤‘ì¹˜
        time_weights = {
            'dawn': [0.8, 0.2, 0.0, 0.0],  # [morning_like, day_like, evening_like, night_like]
            'morning': [1.0, 0.3, 0.0, 0.0],
            'afternoon': [0.0, 1.0, 0.2, 0.0],
            'evening': [0.0, 0.2, 1.0, 0.3],
            'night': [0.0, 0.0, 0.3, 1.0],
            'midnight': [0.0, 0.0, 0.0, 1.0]
        }
        
        # ë‚ ì”¨ë³„ ê°€ì¤‘ì¹˜
        weather_weights = {
            'sunny': [1.0, 0.0, 0.0, 0.0],  # [bright, neutral, dark, stormy]
            'cloudy': [0.3, 1.0, 0.2, 0.0],
            'rainy': [0.0, 0.2, 0.8, 0.3],
            'snowy': [0.5, 0.3, 0.5, 0.0],
            'foggy': [0.0, 0.3, 0.7, 0.0],
            'windy': [0.2, 0.8, 0.3, 0.2],
            'stormy': [0.0, 0.0, 0.5, 1.0]
        }
        
        for scene in scenes:
            time_feature = time_weights.get(scene['time_of_day'], [0.25, 0.25, 0.25, 0.25])
            weather_feature = weather_weights.get(scene['weather'], [0.25, 0.25, 0.25, 0.25])
            
            # ì‹œê°„-ë‚ ì”¨ ì¡°í•©
            combined_feature = [t * w for t, w in zip(time_feature, weather_feature)]
            temporal_features.append(time_feature + weather_feature + combined_feature)
        
        return np.array(temporal_features)
    
    def _encode_scent_notes(self, scent_profile: Dict) -> List[float]:
        """í–¥ìˆ˜ ë…¸íŠ¸ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©"""
        all_notes = scent_profile['primary_notes'] + scent_profile['secondary_notes']
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ê°•ë„ ê³„ì‚°
        encoded = []
        for category, notes in self.scent_categories.items():
            strength = sum(1 for note in all_notes if any(n in note.lower() for n in notes))
            encoded.append(strength / max(1, len(all_notes)))  # ì •ê·œí™”
        
        return encoded

class MovieScentAI:
    """ì˜í™” ì¥ë©´ìš© ìµœê³ ê¸‰ í–¥ìˆ˜ AI ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.processor = MovieScentProcessor()
        self.model = None
        self.training_history = {'train_loss': [], 'val_loss': []}
        
        logger.info("ì˜í™” í–¥ìˆ˜ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def prepare_ultimate_dataset(self, data_path: str, expansion_factor: int = 100):
        """í•œê³„ì¹˜ ë°ì´í„°ì…‹ ì¤€ë¹„"""
        logger.info("í•œê³„ì¹˜ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹œì‘...")
        
        # ê¸°ë³¸ ë°ì´í„° ë¡œë“œ
        movie_data = self.processor.load_movie_data(data_path)
        base_scenes = movie_data['movie_scenes']
        
        # ë°ì´í„°ì…‹ ëŒ€ëŒ€ì  í™•ì¥
        expanded_scenes = self.processor.expand_dataset(base_scenes, expansion_factor)
        
        # íŠ¹ì„± ì¶”ì¶œ
        X, y, encoders = self.processor.extract_features(expanded_scenes)
        
        # ì •ê·œí™”
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        logger.info(f"ìµœì¢… ë°ì´í„°ì…‹: {X_scaled.shape[0]}ê°œ ìƒ˜í”Œ, {X_scaled.shape[1]}ê°œ íŠ¹ì„±")
        
        return X_scaled, y, scaler, encoders
    
    def build_ultimate_model(self, input_dim: int, output_dim: int) -> AdvancedMovieNeuralNetwork:
        """ìµœê³ ê¸‰ ëª¨ë¸ êµ¬ì¶•"""
        logger.info("ìµœê³ ê¸‰ ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì¶• ì¤‘...")
        
        # ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°
        hidden_dims = [1024, 512, 256, 128, 64]
        
        model = AdvancedMovieNeuralNetwork(
            input_dim=input_dim,
            hidden_dims=hidden_dims,
            output_dim=output_dim,
            num_heads=16,  # ë” ë§ì€ ì–´í…ì…˜ í—¤ë“œ
            dropout_rate=0.2,  # ë‚®ì€ ë“œë¡­ì•„ì›ƒìœ¼ë¡œ ë” ë§ì€ ì •ë³´ ë³´ì¡´
            use_attention=True,
            use_residual=True
        )
        
        # ë§¤ê°œë³€ìˆ˜ ìˆ˜ ê³„ì‚°
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        logger.info(f"ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ:")
        logger.info(f"  - ì´ ë§¤ê°œë³€ìˆ˜: {total_params:,}")
        logger.info(f"  - í›ˆë ¨ ê°€ëŠ¥ ë§¤ê°œë³€ìˆ˜: {trainable_params:,}")
        
        return model
    
    def train_to_limit(
        self,
        X: np.ndarray,
        y: np.ndarray,
        max_epochs: int = 1000,
        patience: int = 50,
        batch_size: int = 64
    ) -> Dict[str, Any]:
        """í•œê³„ì¹˜ê¹Œì§€ í›ˆë ¨"""
        logger.info("í•œê³„ì¹˜ í›ˆë ¨ ì‹œì‘...")
        
        # ë°ì´í„° ë¶„í• 
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.15, random_state=42
        )
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = MovieScentDataset(X_train, y_train)
        val_dataset = MovieScentDataset(X_val, y_val)
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        
        # ëª¨ë¸ êµ¬ì¶•
        self.model = self.build_ultimate_model(X.shape[1], y.shape[1])
        
        # ìµœì í™” ì„¤ì •
        optimizer = optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=0.01)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', patience=20, factor=0.5, verbose=True
        )
        
        # ì†ì‹¤ í•¨ìˆ˜ (ë‹¤ì¤‘ ëª©í‘œ)
        mse_loss = nn.MSELoss()
        
        # í›ˆë ¨
        best_val_loss = float('inf')
        patience_counter = 0
        
        for epoch in range(max_epochs):
            # í›ˆë ¨ ë‹¨ê³„
            self.model.train()
            train_loss = 0
            
            for batch_x, batch_y in train_loader:
                optimizer.zero_grad()
                
                outputs = self.model(batch_x)
                
                # ë‹¤ì¤‘ ì†ì‹¤ ê³„ì‚°
                intensity_loss = mse_loss(outputs[:, 0:3], batch_y[:, 0:3])
                profile_loss = mse_loss(outputs[:, 3:], batch_y[:, 3:])
                
                # ê°€ì¤‘ ì´ ì†ì‹¤
                total_loss = 0.4 * intensity_loss + 0.6 * profile_loss
                
                total_loss.backward()
                
                # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                
                optimizer.step()
                train_loss += total_loss.item()
            
            # ê²€ì¦ ë‹¨ê³„
            self.model.eval()
            val_loss = 0
            
            with torch.no_grad():
                for batch_x, batch_y in val_loader:
                    outputs = self.model(batch_x)
                    
                    intensity_loss = mse_loss(outputs[:, 0:3], batch_y[:, 0:3])
                    profile_loss = mse_loss(outputs[:, 3:], batch_y[:, 3:])
                    total_loss = 0.4 * intensity_loss + 0.6 * profile_loss
                    
                    val_loss += total_loss.item()
            
            avg_train_loss = train_loss / len(train_loader)
            avg_val_loss = val_loss / len(val_loader)
            
            self.training_history['train_loss'].append(avg_train_loss)
            self.training_history['val_loss'].append(avg_val_loss)
            
            # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
            scheduler.step(avg_val_loss)
            
            # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                patience_counter = 0
                
                # ìµœê³  ëª¨ë¸ ì €ì¥
                torch.save({
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'epoch': epoch,
                    'loss': best_val_loss,
                    'model_config': {
                        'input_dim': X.shape[1],
                        'output_dim': y.shape[1],
                        'hidden_dims': [1024, 512, 256, 128, 64]
                    }
                }, 'models/ultimate_movie_scent_model.pth')
                
            else:
                patience_counter += 1
                
                if patience_counter >= patience:
                    logger.info(f"ì¡°ê¸° ì¢…ë£Œ (ì—í¬í¬ {epoch+1})")
                    break
            
            if (epoch + 1) % 10 == 0:
                logger.info(f'ì—í¬í¬ [{epoch+1}/{max_epochs}], '
                          f'í›ˆë ¨ ì†ì‹¤: {avg_train_loss:.6f}, '
                          f'ê²€ì¦ ì†ì‹¤: {avg_val_loss:.6f}')
        
        logger.info(f"í›ˆë ¨ ì™„ë£Œ! ìµœê³  ê²€ì¦ ì†ì‹¤: {best_val_loss:.6f}")
        
        return {
            'best_val_loss': best_val_loss,
            'training_history': self.training_history,
            'total_epochs': epoch + 1
        }
    
    def predict_movie_scent(self, scene_data: Dict) -> Dict[str, Any]:
        """ì˜í™” ì¥ë©´ìš© í–¥ìˆ˜ ì˜ˆì¸¡"""
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ë‹¨ì¼ ì¥ë©´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ íŠ¹ì„± ì¶”ì¶œ
        scene_features, _, _ = self.processor.extract_features([scene_data])
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        self.model.eval()
        with torch.no_grad():
            scene_tensor = torch.FloatTensor(scene_features)
            prediction = self.model(scene_tensor).squeeze().numpy()
        
        # ì˜ˆì¸¡ ê²°ê³¼ í•´ì„
        result = {
            'intensity': float(prediction[0] * 10),  # ì—­ì •ê·œí™”
            'longevity': float(prediction[1] * 10),
            'projection': float(prediction[2] * 10),
            'scent_categories': {},
            'confidence': self._calculate_prediction_confidence(prediction),
            'recommended_notes': self._generate_scent_recommendations(prediction[3:])
        }
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê°•ë„
        category_strengths = prediction[3:]
        for i, (category, _) in enumerate(self.processor.scent_categories.items()):
            if i < len(category_strengths):
                result['scent_categories'][category] = float(category_strengths[i])
        
        return result
    
    def _calculate_prediction_confidence(self, prediction: np.ndarray) -> float:
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°"""
        # ì˜ˆì¸¡ê°’ë“¤ì˜ ë¶„ì‚°ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
        variance = np.var(prediction)
        confidence = max(0.1, min(0.95, 1.0 / (1.0 + variance * 10)))
        return confidence
    
    def _generate_scent_recommendations(self, category_strengths: np.ndarray) -> Dict[str, List[str]]:
        """ì¹´í…Œê³ ë¦¬ ê°•ë„ ê¸°ë°˜ í–¥ìˆ˜ ë…¸íŠ¸ ì¶”ì²œ"""
        recommendations = {'primary_notes': [], 'secondary_notes': []}
        
        # ìƒìœ„ ì¹´í…Œê³ ë¦¬ë“¤ ì„ íƒ
        category_items = list(self.processor.scent_categories.items())
        top_indices = np.argsort(category_strengths)[-5:][::-1]  # ìƒìœ„ 5ê°œ
        
        for i, idx in enumerate(top_indices):
            if idx < len(category_items):
                category, notes = category_items[idx]
                strength = category_strengths[idx]
                
                if strength > 0.3:  # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ
                    selected_notes = np.random.choice(notes, 
                                                    min(3, len(notes)), 
                                                    replace=False).tolist()
                    
                    if i < 2:  # ìƒìœ„ 2ê°œëŠ” primary
                        recommendations['primary_notes'].extend(selected_notes[:2])
                    else:  # ë‚˜ë¨¸ì§€ëŠ” secondary
                        recommendations['secondary_notes'].extend(selected_notes[:1])
        
        return recommendations

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        logger.info("ğŸ¬ ì˜í™”ìš© í•œê³„ì¹˜ ëƒ„ìƒˆ êµ¬ì¡° ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ ì‹œì‘")
        
        # AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        movie_ai = MovieScentAI()
        
        # í•œê³„ì¹˜ ë°ì´í„°ì…‹ ì¤€ë¹„
        data_path = "data/movie_scent_database.json"
        X, y, scaler, encoders = movie_ai.prepare_ultimate_dataset(data_path, expansion_factor=200)
        
        logger.info(f"ğŸ“Š ìµœì¢… ë°ì´í„°ì…‹ ê·œëª¨:")
        logger.info(f"   - ìƒ˜í”Œ ìˆ˜: {X.shape[0]:,}")
        logger.info(f"   - íŠ¹ì„± ìˆ˜: {X.shape[1]:,}")
        logger.info(f"   - íƒ€ê²Ÿ ìˆ˜: {y.shape[1]:,}")
        
        # í•œê³„ì¹˜ê¹Œì§€ í›ˆë ¨
        training_results = movie_ai.train_to_limit(
            X, y,
            max_epochs=500,
            patience=30,
            batch_size=128
        )
        
        # ê²°ê³¼ ì¶œë ¥
        logger.info("ğŸ‰ í•œê³„ì¹˜ í›ˆë ¨ ì™„ë£Œ!")
        logger.info(f"ğŸ“ˆ ìµœê³  ê²€ì¦ ì†ì‹¤: {training_results['best_val_loss']:.6f}")
        logger.info(f"ğŸ“ˆ ì´ ì—í¬í¬: {training_results['total_epochs']}")
        
        # ì „ì²˜ë¦¬ ë„êµ¬ ì €ì¥
        with open('models/movie_scent_preprocessor.pkl', 'wb') as f:
            pickle.dump({
                'scaler': scaler,
                'encoders': encoders,
                'processor': movie_ai.processor
            }, f)
        
        # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
        test_scene = {
            "scene_type": "romantic",
            "location": "beach_sunset",
            "time_of_day": "sunset",
            "weather": "warm",
            "emotions": ["love", "passion", "serenity"],
            "visual_elements": ["ocean", "sand", "golden_light"],
            "scent_profile": {
                "primary_notes": ["sea breeze", "white flowers"],
                "secondary_notes": ["vanilla", "amber"],
                "intensity": 6,
                "longevity": 7,
                "projection": 5,
                "mood": "romantic"
            }
        }
        
        prediction = movie_ai.predict_movie_scent(test_scene)
        
        logger.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ê²°ê³¼:")
        logger.info(f"   - ê°•ë„: {prediction['intensity']:.2f}/10")
        logger.info(f"   - ì§€ì†ì„±: {prediction['longevity']:.2f}/10")
        logger.info(f"   - íˆ¬ì‚¬ë ¥: {prediction['projection']:.2f}/10")
        logger.info(f"   - ì‹ ë¢°ë„: {prediction['confidence']:.3f}")
        
        top_categories = sorted(prediction['scent_categories'].items(), 
                               key=lambda x: x[1], reverse=True)[:5]
        logger.info("   - ìƒìœ„ í–¥ìˆ˜ ì¹´í…Œê³ ë¦¬:")
        for category, strength in top_categories:
            logger.info(f"     * {category}: {strength:.3f}")
        
        logger.info("âœ… ì˜í™”ìš© ëƒ„ìƒˆ êµ¬ì¡° ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ ì™„ì„±!")
        
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    main()