from __future__ import annotations

import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
import json
import ast
import re
from dataclasses import dataclass
import logging

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, MultiLabelBinarizer
from sklearn.feature_extraction.text import TfidfVectorizer
import torch
import torch.nn as nn
from sentence_transformers import SentenceTransformer

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ProcessedFragranceData:
    """ì „ì²˜ë¦¬ëœ í–¥ìˆ˜ ë°ì´í„° êµ¬ì¡°"""
    # ì›ë³¸ ì •ë³´
    name: str
    description: str
    rating: float
    rating_count: int
    gender: str
    
    # ì²˜ë¦¬ëœ íŠ¹ì„±ë“¤
    main_accords: List[str]
    top_notes: List[str]
    middle_notes: List[str]
    base_notes: List[str]
    
    # ì¸ì½”ë”©ëœ íŠ¹ì„±ë“¤
    accord_encoding: np.ndarray
    note_encoding: np.ndarray
    text_embedding: np.ndarray
    gender_encoding: int
    
    # í’ˆì§ˆ ì§€í‘œ
    popularity_score: float
    complexity_score: float
    quality_score: float


class AdvancedFragranceDataProcessor:
    """ê³ ê¸‰ í–¥ìˆ˜ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"):
        self.embedding_model = SentenceTransformer(embedding_model)
        
        # ì¸ì½”ë”ë“¤ ì´ˆê¸°í™”
        self.mlb_accords = MultiLabelBinarizer()
        self.mlb_notes = MultiLabelBinarizer()
        self.gender_encoder = LabelEncoder()
        self.scaler = StandardScaler()
        
        # í–¥ë£Œ ë…¸íŠ¸ ì‚¬ì „ (NLP íŒŒì‹±ìš©)
        self.note_patterns = {
            'citrus': ['lemon', 'orange', 'bergamot', 'lime', 'grapefruit', 'mandarin', 'citrus'],
            'floral': ['rose', 'jasmine', 'lavender', 'lily', 'iris', 'peony', 'tuberose', 'violet', 'freesia'],
            'fruity': ['apple', 'strawberry', 'raspberry', 'blackcurrant', 'peach', 'pear', 'plum'],
            'woody': ['cedar', 'sandalwood', 'patchouli', 'vetiver', 'pine', 'cypress', 'guaiac'],
            'spicy': ['pepper', 'cardamom', 'cinnamon', 'nutmeg', 'ginger', 'saffron', 'clove'],
            'herbal': ['mint', 'basil', 'thyme', 'rosemary', 'sage', 'bay'],
            'sweet': ['vanilla', 'caramel', 'honey', 'tonka', 'praline', 'chocolate'],
            'fresh': ['marine', 'aquatic', 'ozone', 'cucumber', 'watermelon'],
            'animalic': ['musk', 'ambergris', 'civet', 'castoreum'],
            'resinous': ['amber', 'benzoin', 'labdanum', 'frankincense', 'myrrh']
        }
        
        # í†µê³„ ì •ë³´
        self.processing_stats = {}
        
    def load_and_clean_data(self, file_path: str) -> pd.DataFrame:
        """ì›ì‹œ ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ë¦¬"""
        logger.info("ğŸ“‚ ì›ì‹œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
            logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰")
            
        except UnicodeDecodeError:
            df = pd.read_csv(file_path, encoding='cp949')  # Windows ì¸ì½”ë”©
            logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ (CP949): {len(df)} í–‰")
        
        # ê¸°ë³¸ ì •ë³´ ì¶œë ¥
        logger.info(f"ğŸ“Š ì»¬ëŸ¼: {list(df.columns)}")
        
        # ë°ì´í„° ì •ë¦¬
        df_clean = self._clean_basic_data(df)
        
        self.processing_stats['original_count'] = len(df)
        self.processing_stats['cleaned_count'] = len(df_clean)
        self.processing_stats['removed_count'] = len(df) - len(df_clean)
        
        return df_clean
    
    def _clean_basic_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê¸°ë³¸ ë°ì´í„° ì •ë¦¬"""
        logger.info("ğŸ§¹ ê¸°ë³¸ ë°ì´í„° ì •ë¦¬ ì¤‘...")
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        df.columns = df.columns.str.strip()
        
        # ê²°ì¸¡ì¹˜ê°€ ë§ì€ í–‰ ì œê±°
        df = df.dropna(subset=['Name', 'Description'])
        
        # Rating Value ì²˜ë¦¬ (ë¬¸ìì—´ë¡œ ëœ ê²½ìš° ì²˜ë¦¬)
        df['Rating Value'] = pd.to_numeric(df['Rating Value'], errors='coerce')
        
        # Rating Count ì²˜ë¦¬ (ì‰¼í‘œ ì œê±°)
        df['Rating Count'] = df['Rating Count'].astype(str).str.replace(',', '')
        df['Rating Count'] = pd.to_numeric(df['Rating Count'], errors='coerce')
        
        # ê²°ì¸¡ì¹˜ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´
        df['Rating Value'] = df['Rating Value'].fillna(3.5)  # í‰ê·  í‰ì 
        df['Rating Count'] = df['Rating Count'].fillna(1)    # ìµœì†Œ ì¹´ìš´íŠ¸
        
        # Main Accords ì •ë¦¬ (ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜)
        df['Main Accords'] = df['Main Accords'].apply(self._parse_list_string)
        
        # Descriptionì—ì„œ ë…¸íŠ¸ ì •ë³´ ì¶”ì¶œ
        df['Top Notes'] = df['Description'].apply(lambda x: self._extract_notes(x, 'top'))
        df['Middle Notes'] = df['Description'].apply(lambda x: self._extract_notes(x, 'middle'))
        df['Base Notes'] = df['Description'].apply(lambda x: self._extract_notes(x, 'base'))
        
        logger.info(f"âœ… ì •ë¦¬ ì™„ë£Œ: {len(df)} í–‰ ìœ ì§€")
        
        return df
    
    def _parse_list_string(self, list_str: str) -> List[str]:
        """ë¬¸ìì—´ë¡œ ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if pd.isna(list_str) or not list_str.strip():
            return []
        
        try:
            # ['item1', 'item2'] í˜•íƒœ íŒŒì‹±
            parsed = ast.literal_eval(list_str)
            if isinstance(parsed, list):
                return [item.strip().lower() for item in parsed if item.strip()]
        except (ValueError, SyntaxError):
            pass
        
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í˜•íƒœ ì²˜ë¦¬
        if ',' in list_str:
            return [item.strip().lower() for item in list_str.split(',') if item.strip()]
        
        return [list_str.strip().lower()] if list_str.strip() else []
    
    def _extract_notes(self, description: str, note_type: str) -> List[str]:
        """ì„¤ëª…ì—ì„œ ë…¸íŠ¸ ì •ë³´ ì¶”ì¶œ"""
        if pd.isna(description):
            return []
        
        description = description.lower()
        
        # ë…¸íŠ¸ íƒ€ì…ë³„ íŒ¨í„´ ì°¾ê¸°
        if note_type == 'top':
            patterns = [r'top notes? are? ([^;.]+)', r'opens? with ([^;.]+)']
        elif note_type == 'middle':
            patterns = [r'middle notes? are? ([^;.]+)', r'heart notes? are? ([^;.]+)']
        else:  # base
            patterns = [r'base notes? are? ([^;.]+)', r'dries? down to ([^;.]+)']
        
        extracted_notes = []
        
        for pattern in patterns:
            matches = re.findall(pattern, description)
            for match in matches:
                # ë…¸íŠ¸ë“¤ì„ íŒŒì‹± (ì‰¼í‘œì™€ 'and'ë¡œ êµ¬ë¶„)
                notes_text = re.sub(r'\s+and\s+', ', ', match)
                notes = [note.strip() for note in notes_text.split(',')]
                
                # ê° ë…¸íŠ¸ë¥¼ ì •ë¦¬
                for note in notes:
                    note = re.sub(r'\([^)]*\)', '', note).strip()  # ê´„í˜¸ ë‚´ìš© ì œê±°
                    if note and len(note) > 2:
                        extracted_notes.append(note)
        
        return list(set(extracted_notes))  # ì¤‘ë³µ ì œê±°
    
    def create_advanced_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê³ ê¸‰ íŠ¹ì„±ë“¤ ìƒì„±"""
        logger.info("ğŸ”¬ ê³ ê¸‰ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # 1. ì¸ê¸°ë„ ì ìˆ˜ (í‰ì  * log(í‰ì  ìˆ˜))
        df['popularity_score'] = df['Rating Value'] * np.log1p(df['Rating Count'])
        
        # 2. ë³µí•©ì„± ì ìˆ˜ (ì‚¬ìš©ëœ ë…¸íŠ¸ ìˆ˜)
        df['complexity_score'] = (
            df['Top Notes'].apply(len) + 
            df['Middle Notes'].apply(len) + 
            df['Base Notes'].apply(len)
        )
        
        # 3. í’ˆì§ˆ ì ìˆ˜ (í‰ì ê³¼ ë³µí•©ì„±ì˜ ì¡°í•©)
        df['quality_score'] = (
            df['Rating Value'] * 0.7 + 
            (df['complexity_score'] / df['complexity_score'].max()) * 3 * 0.3
        )
        
        # 4. ì „ì²´ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        df['all_notes'] = df.apply(
            lambda row: row['Top Notes'] + row['Middle Notes'] + row['Base Notes'], 
            axis=1
        )
        
        # 5. ì„±ë³„ ì„ í˜¸ë„ ì¸ì½”ë”©
        df['gender_clean'] = df['Gender'].apply(self._clean_gender)
        
        # 6. ë¸Œëœë“œ ì¶”ì¶œ
        df['brand'] = df['Name'].apply(self._extract_brand)
        
        # 7. í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
        logger.info("ğŸ§  í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘...")
        descriptions = df['Description'].fillna('').tolist()
        embeddings = self.embedding_model.encode(descriptions, show_progress_bar=True)
        df['text_embedding'] = list(embeddings)
        
        # 8. í–¥ë£Œ ê³„ì—´ ì ìˆ˜ ê³„ì‚°
        for family, keywords in self.note_patterns.items():
            df[f'{family}_score'] = df['all_notes'].apply(
                lambda notes: self._calculate_family_score(notes, keywords)
            )
        
        logger.info("âœ… ê³ ê¸‰ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return df
    
    def _clean_gender(self, gender_str: str) -> str:
        """ì„±ë³„ ì •ë³´ ì •ë¦¬"""
        if pd.isna(gender_str):
            return 'unisex'
        
        gender_str = gender_str.lower()
        
        if 'women' in gender_str and 'men' in gender_str:
            return 'unisex'
        elif 'women' in gender_str:
            return 'female'
        elif 'men' in gender_str:
            return 'male'
        else:
            return 'unisex'
    
    def _extract_brand(self, name: str) -> str:
        """ì œí’ˆëª…ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ"""
        if pd.isna(name):
            return 'unknown'
        
        # ì¼ë°˜ì ì¸ ë¸Œëœë“œ íŒ¨í„´ë“¤
        brand_patterns = [
            r'([A-Za-z\s]+?)\s+for\s+(women|men)',
            r'by\s+([A-Za-z\s]+?)is',
            r'([A-Za-z\s]+?)\s+Perfumes',
        ]
        
        for pattern in brand_patterns:
            match = re.search(pattern, name)
            if match:
                return match.group(1).strip()
        
        # ë§ˆì§€ë§‰ ì‹œë„: ì²« ë²ˆì§¸ ë‹¨ì–´ë“¤ ì‚¬ìš©
        words = name.split()
        if len(words) >= 2:
            return ' '.join(words[-2:]) if 'for' not in words[-2:] else words[0]
        
        return 'unknown'
    
    def _calculate_family_score(self, notes: List[str], keywords: List[str]) -> float:
        """íŠ¹ì • í–¥ë£Œ ê³„ì—´ì˜ ì ìˆ˜ ê³„ì‚°"""
        if not notes:
            return 0.0
        
        matches = 0
        for note in notes:
            for keyword in keywords:
                if keyword in note.lower():
                    matches += 1
                    break
        
        return matches / len(notes)
    
    def encode_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
        """ëª¨ë“  íŠ¹ì„±ë“¤ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ì¸ì½”ë”©"""
        logger.info("ğŸ”¢ íŠ¹ì„± ì¸ì½”ë”© ì¤‘...")
        
        # 1. Multi-label ì¸ì½”ë”© (Main Accords)
        accord_matrix = self.mlb_accords.fit_transform(df['Main Accords'])
        logger.info(f"ğŸ“Š Accords ì°¨ì›: {accord_matrix.shape[1]}")
        
        # 2. ë…¸íŠ¸ë“¤ ì¸ì½”ë”©
        all_notes_combined = df['all_notes']
        note_matrix = self.mlb_notes.fit_transform(all_notes_combined)
        logger.info(f"ğŸ“Š Notes ì°¨ì›: {note_matrix.shape[1]}")
        
        # 3. ì„±ë³„ ì¸ì½”ë”©
        gender_encoded = self.gender_encoder.fit_transform(df['gender_clean'])
        
        # 4. í…ìŠ¤íŠ¸ ì„ë² ë”© ìŠ¤íƒ
        text_embeddings = np.vstack(df['text_embedding'].tolist())
        logger.info(f"ğŸ“Š Text embedding ì°¨ì›: {text_embeddings.shape[1]}")
        
        # 5. ìˆ˜ì¹˜í˜• íŠ¹ì„±ë“¤
        numeric_features = df[[
            'Rating Value', 'Rating Count', 'popularity_score', 
            'complexity_score', 'quality_score'
        ] + [f'{family}_score' for family in self.note_patterns.keys()]].values
        
        # 6. ì •ê·œí™”
        numeric_features_scaled = self.scaler.fit_transform(numeric_features)
        
        # 7. ëª¨ë“  íŠ¹ì„± ê²°í•©
        X = np.hstack([
            accord_matrix,           # Accord features
            note_matrix,            # Note features  
            text_embeddings,        # Text embeddings
            numeric_features_scaled, # Numeric features
            gender_encoded.reshape(-1, 1)  # Gender
        ])
        
        # 8. íƒ€ê²Ÿ ë³€ìˆ˜ (í‰ì  ì˜ˆì¸¡ìš©)
        y = df['Rating Value'].values
        
        # 9. ë©”íƒ€ë°ì´í„°
        metadata = {
            'feature_dimensions': {
                'accords': accord_matrix.shape[1],
                'notes': note_matrix.shape[1], 
                'text_embeddings': text_embeddings.shape[1],
                'numeric': numeric_features_scaled.shape[1],
                'gender': 1,
                'total': X.shape[1]
            },
            'accord_classes': list(self.mlb_accords.classes_),
            'note_classes': list(self.mlb_notes.classes_),
            'gender_classes': list(self.gender_encoder.classes_),
            'processing_stats': self.processing_stats
        }
        
        logger.info(f"âœ… ì¸ì½”ë”© ì™„ë£Œ: {X.shape[0]} ìƒ˜í”Œ, {X.shape[1]} íŠ¹ì„±")
        
        return X, y, metadata
    
    def create_training_data(self, X: np.ndarray, y: np.ndarray, df: pd.DataFrame) -> Dict[str, Any]:
        """í•™ìŠµìš© ë°ì´í„° ìƒì„±"""
        logger.info("ğŸ“š í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘...")
        
        # 1. Train/Validation/Test ë¶„í• 
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y, test_size=0.15, random_state=42, stratify=pd.cut(y, bins=5, labels=False)
        )
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=0.18, random_state=42,  # 0.18 * 0.85 â‰ˆ 0.15
            stratify=pd.cut(y_temp, bins=5, labels=False)
        )
        
        # 2. ì¶”ê°€ í•™ìŠµ íƒœìŠ¤í¬ë¥¼ ìœ„í•œ ë°ì´í„°
        
        # 2-1. ì„±ë³„ ì˜ˆì¸¡ íƒœìŠ¤í¬
        gender_labels = self.gender_encoder.transform(df['gender_clean'])
        
        # 2-2. ì¸ê¸°ë„ ì˜ˆì¸¡ íƒœìŠ¤í¬ (ì¸ê¸°ë„ë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ)
        popularity_labels = pd.cut(
            df['popularity_score'], 
            bins=3, 
            labels=['low', 'medium', 'high']
        ).codes
        
        # 2-3. ë³µí•©ì„± ì˜ˆì¸¡ íƒœìŠ¤í¬
        complexity_labels = pd.cut(
            df['complexity_score'],
            bins=3,
            labels=['simple', 'medium', 'complex']
        ).codes
        
        # 3. ë°ì´í„° í…ì„œ ë³€í™˜
        training_data = {
            'X_train': torch.FloatTensor(X_train),
            'X_val': torch.FloatTensor(X_val),
            'X_test': torch.FloatTensor(X_test),
            
            # í‰ì  ì˜ˆì¸¡
            'y_rating_train': torch.FloatTensor(y_train),
            'y_rating_val': torch.FloatTensor(y_val), 
            'y_rating_test': torch.FloatTensor(y_test),
            
            # ì„±ë³„ ì˜ˆì¸¡  
            'y_gender_train': torch.LongTensor(gender_labels[:len(X_train)]),
            'y_gender_val': torch.LongTensor(gender_labels[len(X_train):len(X_train)+len(X_val)]),
            'y_gender_test': torch.LongTensor(gender_labels[-len(X_test):]),
            
            # ì¸ê¸°ë„ ì˜ˆì¸¡
            'y_popularity_train': torch.LongTensor(popularity_labels[:len(X_train)]),
            'y_popularity_val': torch.LongTensor(popularity_labels[len(X_train):len(X_train)+len(X_val)]),
            'y_popularity_test': torch.LongTensor(popularity_labels[-len(X_test):]),
            
            # ë³µí•©ì„± ì˜ˆì¸¡
            'y_complexity_train': torch.LongTensor(complexity_labels[:len(X_train)]),
            'y_complexity_val': torch.LongTensor(complexity_labels[len(X_train):len(X_train)+len(X_val)]),
            'y_complexity_test': torch.LongTensor(complexity_labels[-len(X_test):])
        }
        
        logger.info(f"âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
        logger.info(f"   ğŸ“Š Train: {len(X_train)} ìƒ˜í”Œ")
        logger.info(f"   ğŸ“Š Validation: {len(X_val)} ìƒ˜í”Œ")
        logger.info(f"   ğŸ“Š Test: {len(X_test)} ìƒ˜í”Œ")
        
        return training_data
    
    def save_processed_data(
        self, 
        training_data: Dict[str, Any], 
        metadata: Dict[str, Any], 
        df: pd.DataFrame,
        output_dir: str = "data/processed"
    ):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘: {output_path}")
        
        # 1. í•™ìŠµ ë°ì´í„° ì €ì¥
        torch.save(training_data, output_path / "training_data.pt")
        
        # 2. ë©”íƒ€ë°ì´í„° ì €ì¥
        with open(output_path / "metadata.json", 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # 3. ì „ì²˜ë¦¬ëœ DataFrame ì €ì¥
        df.to_csv(output_path / "processed_perfume_data.csv", index=False, encoding='utf-8')
        
        # 4. ì¸ì½”ë”ë“¤ ì €ì¥
        import joblib
        joblib.dump(self.mlb_accords, output_path / "accord_encoder.pkl")
        joblib.dump(self.mlb_notes, output_path / "note_encoder.pkl")
        joblib.dump(self.gender_encoder, output_path / "gender_encoder.pkl")
        joblib.dump(self.scaler, output_path / "scaler.pkl")
        
        logger.info("âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        
        # 5. ì²˜ë¦¬ ìš”ì•½ ì¶œë ¥
        self._print_processing_summary(metadata, df)
    
    def _print_processing_summary(self, metadata: Dict[str, Any], df: pd.DataFrame):
        """ì²˜ë¦¬ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š DATA PROCESSING SUMMARY")
        print("="*80)
        
        print(f"ğŸ“ˆ ì›ë³¸ ë°ì´í„°: {metadata['processing_stats']['original_count']:,} í–‰")
        print(f"âœ… ì •ë¦¬ëœ ë°ì´í„°: {metadata['processing_stats']['cleaned_count']:,} í–‰")
        print(f"âŒ ì œê±°ëœ ë°ì´í„°: {metadata['processing_stats']['removed_count']:,} í–‰")
        print(f"ğŸ“Š íŠ¹ì„± ì°¨ì›: {metadata['feature_dimensions']['total']:,}")
        
        print(f"\nğŸ­ íŠ¹ì„± ë¶„í¬:")
        for feature_type, dim in metadata['feature_dimensions'].items():
            if feature_type != 'total':
                print(f"   â€¢ {feature_type}: {dim}")
        
        print(f"\nğŸ·ï¸  í´ë˜ìŠ¤ ì •ë³´:")
        print(f"   â€¢ Accords: {len(metadata['accord_classes'])} ì¢…ë¥˜")
        print(f"   â€¢ Notes: {len(metadata['note_classes'])} ì¢…ë¥˜") 
        print(f"   â€¢ Gender: {len(metadata['gender_classes'])} ì¢…ë¥˜")
        
        print(f"\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ì§€í‘œ:")
        print(f"   â€¢ í‰ê·  í‰ì : {df['Rating Value'].mean():.2f}")
        print(f"   â€¢ í‰ê·  ë³µí•©ì„±: {df['complexity_score'].mean():.1f}")
        print(f"   â€¢ í‰ê·  ì¸ê¸°ë„: {df['popularity_score'].mean():.1f}")
        
        print("\nğŸ¯ ìƒì„±ëœ í•™ìŠµ íƒœìŠ¤í¬:")
        print("   â€¢ í‰ì  ì˜ˆì¸¡ (íšŒê·€)")
        print("   â€¢ ì„±ë³„ ë¶„ë¥˜")
        print("   â€¢ ì¸ê¸°ë„ ë¶„ë¥˜")
        print("   â€¢ ë³µí•©ì„± ë¶„ë¥˜")
        
        print("="*80)


def main():
    """ë©”ì¸ ë°ì´í„° ì²˜ë¦¬ ì‹¤í–‰"""
    print("ğŸš€ ê³ ê¸‰ í–¥ìˆ˜ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘!")
    
    # ë°ì´í„° ê²½ë¡œ
    raw_data_path = "data/raw/raw_perfume_data.csv"
    
    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = AdvancedFragranceDataProcessor()
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ ë° ì •ë¦¬
        df_clean = processor.load_and_clean_data(raw_data_path)
        
        # 2. ê³ ê¸‰ íŠ¹ì„± ìƒì„±
        df_enhanced = processor.create_advanced_features(df_clean)
        
        # 3. íŠ¹ì„± ì¸ì½”ë”©
        X, y, metadata = processor.encode_features(df_enhanced)
        
        # 4. í•™ìŠµ ë°ì´í„° ìƒì„±
        training_data = processor.create_training_data(X, y, df_enhanced)
        
        # 5. ë°ì´í„° ì €ì¥
        processor.save_processed_data(training_data, metadata, df_enhanced)
        
        print("\nğŸ‰ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()