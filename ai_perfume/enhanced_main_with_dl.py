#!/usr/bin/env python3
"""
ë”¥ëŸ¬ë‹ì´ í†µí•©ëœ ìµœì‹  í–¥ìˆ˜ AI ì‹œìŠ¤í…œ
"""

from __future__ import annotations

import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
import json
import logging
import time

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

# ê¸°ì¡´ ì‹œìŠ¤í…œ ì„í¬íŠ¸
from models.text_analyzer import TextAnalyzer
from models.advanced_recipe_generator import AdvancedRecipeGenerator
from core.database import Session, Recipe, Feedback, init_db, get_db_session

# ë”¥ëŸ¬ë‹ í†µí•© ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from core.deep_learning_integration import DeepLearningPerfumePredictor, EnhancedPerfumeGenerator
    DL_AVAILABLE = True
except ImportError as e:
    print(f"Warning: ë”¥ëŸ¬ë‹ ëª¨ë“ˆ ì‚¬ìš© ë¶ˆê°€: {e}")
    DL_AVAILABLE = False

# ê¸°íƒ€ ê³ ê¸‰ ì‹œìŠ¤í…œë“¤
try:
    from core.rag_system import FragranceRAGSystem
    RAG_AVAILABLE = True
except ImportError as e:
    print(f"Warning: RAG system not available: {e}")
    RAG_AVAILABLE = False

try:
    from core.korean_llm_integration import KoreanFragranceLLMSystem
    KOREAN_LLM_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Korean LLM system not available: {e}")
    KOREAN_LLM_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DeepLearningEnhancedPerfumeAI:
    """ë”¥ëŸ¬ë‹ì´ í†µí•©ëœ ì°¨ì„¸ëŒ€ í–¥ìˆ˜ AI ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        logger.info("ğŸš€ ë”¥ëŸ¬ë‹ í†µí•© í–¥ìˆ˜ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # ê¸°ë³¸ ì‹œìŠ¤í…œë“¤
        self.text_analyzer = TextAnalyzer()
        self.advanced_generator = AdvancedRecipeGenerator()
        
        # ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.dl_predictor = None
        self.enhanced_generator = None
        self._initialize_deep_learning()
        
        # ì„ íƒì  ê³ ê¸‰ ì‹œìŠ¤í…œë“¤
        self.rag_system = None
        self.korean_llm_system = None
        self._initialize_optional_systems()
        
        # ì‹œìŠ¤í…œ ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            'total_requests': 0,
            'successful_generations': 0,
            'dl_enhanced_generations': 0,
            'average_response_time': 0.0,
            'system_components_active': self._get_active_components()
        }
        
        logger.info("âœ… ë”¥ëŸ¬ë‹ í†µí•© í–¥ìˆ˜ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        self._print_system_status()
    
    def _initialize_deep_learning(self):
        """ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        if not DL_AVAILABLE:
            logger.warning("âŒ ë”¥ëŸ¬ë‹ ëª¨ë“ˆ ì‚¬ìš© ë¶ˆê°€")
            return
        
        try:
            # ë”¥ëŸ¬ë‹ ëª¨ë¸ ê²½ë¡œ
            model_path = "models/perfume_dl_model.pth"
            preprocessor_path = "data/processed/preprocessor_tools.pkl"  
            metadata_path = "data/processed/metadata.json"
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not all(Path(p).exists() for p in [model_path, preprocessor_path, metadata_path]):
                logger.warning("âš ï¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ íŒŒì¼ë“¤ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ - í›ˆë ¨ ì™„ë£Œ í›„ ì¬ì‹œì‘ í•„ìš”")
                return
            
            # ë”¥ëŸ¬ë‹ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
            self.dl_predictor = DeepLearningPerfumePredictor(
                model_path=model_path,
                preprocessor_path=preprocessor_path,
                metadata_path=metadata_path
            )
            
            # í–¥ìƒëœ ìƒì„±ê¸° ì´ˆê¸°í™”
            self.enhanced_generator = EnhancedPerfumeGenerator(self.dl_predictor)
            
            logger.info("âœ… ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _initialize_optional_systems(self):
        """ì„ íƒì  ê³ ê¸‰ ì‹œìŠ¤í…œë“¤ ì´ˆê¸°í™”"""
        
        # RAG ì‹œìŠ¤í…œ
        if RAG_AVAILABLE:
            try:
                self.rag_system = FragranceRAGSystem()
                logger.info("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # í•œêµ­ì–´ LLM ì‹œìŠ¤í…œ
        if KOREAN_LLM_AVAILABLE:
            try:
                self.korean_llm_system = KoreanFragranceLLMSystem()
                logger.info("âœ… í•œêµ­ì–´ LLM ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ í•œêµ­ì–´ LLM ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _get_active_components(self) -> List[str]:
        """í™œì„±í™”ëœ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ëª©ë¡"""
        active = ['ê¸°ë³¸_í…ìŠ¤íŠ¸_ë¶„ì„', 'ê³ ê¸‰_ë ˆì‹œí”¼_ìƒì„±']
        
        if self.dl_predictor:
            active.append('ë”¥ëŸ¬ë‹_ì˜ˆì¸¡')
        if self.enhanced_generator:
            active.append('ë”¥ëŸ¬ë‹_í†µí•©_ìƒì„±')
        if self.rag_system:
            active.append('RAG_ì§€ì‹ë² ì´ìŠ¤')
        if self.korean_llm_system:
            active.append('í•œêµ­ì–´_LLM')
        
        return active
    
    def _print_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ¤– DEEP LEARNING ENHANCED PERFUME AI SYSTEM")
        print("="*80)
        
        active_components = self._get_active_components()
        print(f"ğŸ“Š í™œì„± ì»´í¬ë„ŒíŠ¸: {len(active_components)}ê°œ")
        for i, component in enumerate(active_components, 1):
            status = "âœ…" if component != "ë”¥ëŸ¬ë‹_ì˜ˆì¸¡" or self.dl_predictor else "âš ï¸"
            print(f"   {i}. {status} {component}")
        
        # ì‹œìŠ¤í…œ íŠ¹ì„±
        features = [
            "ğŸ§  Transformer ê¸°ë°˜ ë ˆì‹œí”¼ ìƒì„±",
            "ğŸ¤– ë”¥ëŸ¬ë‹ í‰ì /ì„±ë³„ ì˜ˆì¸¡" if self.dl_predictor else "âŒ ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ ëŒ€ê¸°ì¤‘",
            "ğŸ“ˆ ML ê¸°ë°˜ ë…¸íŠ¸ ì¶”ì²œ" if self.enhanced_generator else "âŒ í–¥ìƒëœ ìƒì„±ê¸° ëŒ€ê¸°ì¤‘",
            "ğŸ” RAG ì „ë¬¸ ì§€ì‹ ê²€ìƒ‰" if self.rag_system else "âŒ RAG ì‹œìŠ¤í…œ ë¹„í™œì„±",
            "ğŸ‡°ğŸ‡· í•œêµ­ì–´ LLM í†µí•©" if self.korean_llm_system else "âŒ í•œêµ­ì–´ LLM ë¹„í™œì„±",
            "ğŸ’¾ ì§€ì†ì  í•™ìŠµ ë° í”¼ë“œë°±",
            "ğŸ¨ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ í–¥ë£Œ ìµœì í™”"
        ]
        
        print(f"\nğŸš€ ì‹œìŠ¤í…œ ê¸°ëŠ¥:")
        for feature in features:
            print(f"   {feature}")
        
        if self.dl_predictor:
            dl_info = self.dl_predictor.get_model_info()
            print(f"\nğŸ¤– ë”¥ëŸ¬ë‹ ëª¨ë¸ ì •ë³´:")
            print(f"   - ëª¨ë¸ ìƒíƒœ: {'í™œì„±' if dl_info['model_available'] else 'ë¹„í™œì„±'}")
            print(f"   - ì…ë ¥ ì°¨ì›: {dl_info['metadata'].get('feature_dim', 'N/A')}")
            print(f"   - ì¶œë ¥ ì°¨ì›: {dl_info['metadata'].get('target_dim', 'N/A')}")
            print(f"   - í›ˆë ¨ ìƒ˜í”Œ: {dl_info['metadata'].get('num_samples', 'N/A')}")
        
        print("="*80)
    
    def generate_perfume_with_deep_learning(
        self,
        text: str,
        user_preferences: Optional[Dict] = None,
        use_rag: bool = True,
        generate_korean_content: bool = True
    ) -> Dict[str, Any]:
        """ë”¥ëŸ¬ë‹ì´ í†µí•©ëœ í–¥ìˆ˜ ìƒì„±"""
        
        start_time = time.time()
        self.performance_stats['total_requests'] += 1
        
        logger.info(f"ğŸ¯ ë”¥ëŸ¬ë‹ í†µí•© í–¥ìˆ˜ ìƒì„± ìš”ì²­: '{text[:50]}...'")
        
        try:
            # 1. ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„
            logger.info("ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘...")
            analysis = self.text_analyzer.analyze(text)
            
            # 2. ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
            if self.enhanced_generator:
                logger.info("ğŸ¤– ë”¥ëŸ¬ë‹ í†µí•© ë ˆì‹œí”¼ ìƒì„± ì¤‘...")
                recipe = self.enhanced_generator.generate_enhanced_recipe(
                    text, analysis, user_preferences
                )
                self.performance_stats['dl_enhanced_generations'] += 1
            else:
                logger.info("âš¡ ê¸°ë³¸ Transformer ë ˆì‹œí”¼ ìƒì„± ì¤‘...")
                recipe = self._generate_basic_recipe(analysis)
            
            # 3. RAG ì‹œìŠ¤í…œìœ¼ë¡œ ë ˆì‹œí”¼ ê°•í™” (ì„ íƒì‚¬í•­)
            if use_rag and self.rag_system:
                logger.info("ğŸ” RAG ì§€ì‹ë² ì´ìŠ¤ë¡œ ë ˆì‹œí”¼ ê°•í™” ì¤‘...")
                try:
                    enhanced_recipe = self.rag_system.enhance_recipe_with_context(
                        recipe, f"ê°ì •: {list(analysis['emotions'].keys())}"
                    )
                    recipe.update(enhanced_recipe)
                except Exception as e:
                    logger.warning(f"RAG ê°•í™” ì‹¤íŒ¨: {e}")
            
            # 4. í•œêµ­ì–´ ì½˜í…ì¸  ìƒì„± (ì„ íƒì‚¬í•­)
            korean_content = {}
            if generate_korean_content and self.korean_llm_system:
                logger.info("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì½˜í…ì¸  ìƒì„± ì¤‘...")
                try:
                    recipe_data = {
                        'top_notes': recipe.get('top_notes', []),
                        'middle_notes': recipe.get('middle_notes', []),
                        'base_notes': recipe.get('base_notes', []),
                        'emotions': list(analysis['emotions'].keys())[:3],
                        'intensity': recipe.get('intensity', 5.0)
                    }
                    korean_content = self.korean_llm_system.generate_korean_fragrance_content(
                        recipe_data,
                        content_types=['name', 'description', 'story'],
                        model_preference='kogpt2'
                    )
                except Exception as e:
                    logger.warning(f"í•œêµ­ì–´ ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}")
            
            # 5. ìµœì¢… ê²°ê³¼ í†µí•©
            final_result = self._combine_results(recipe, korean_content, analysis, text)
            
            # 6. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            db_recipe_id = self._save_to_database(final_result, text)
            final_result['recipe_id'] = db_recipe_id
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_performance_stats(processing_time, success=True)
            
            final_result['processing_time'] = processing_time
            final_result['system_info'] = {
                'deep_learning_enhanced': bool(self.enhanced_generator),
                'rag_enhanced': use_rag and self.rag_system,
                'korean_content_generated': bool(korean_content),
                'generation_quality': self._assess_generation_quality(final_result),
                'active_components': len(self._get_active_components())
            }
            
            logger.info(f"âœ… ë”¥ëŸ¬ë‹ í†µí•© í–¥ìˆ˜ ìƒì„± ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ í–¥ìˆ˜ ìƒì„± ì‹¤íŒ¨: {e}")
            self._update_performance_stats(time.time() - start_time, success=False)
            return self._generate_fallback_recipe(text)
    
    def _generate_basic_recipe(self, analysis: Dict) -> Dict[str, Any]:
        """ê¸°ë³¸ ë ˆì‹œí”¼ ìƒì„± (ë”¥ëŸ¬ë‹ ì—†ì´)"""
        import torch
        
        emotion_scores = torch.tensor(
            [list(analysis['emotions'].values())],
            dtype=torch.float32
        )
        
        return self.advanced_generator.generate_recipe(
            analysis['embeddings'],
            emotion_scores,
            temperature=0.8,
            top_k=5
        )
    
    def _combine_results(self, recipe: Dict, korean_content: Dict, 
                        analysis: Dict, original_text: str) -> Dict[str, Any]:
        """ëª¨ë“  ê²°ê³¼ë¥¼ í†µí•©"""
        
        combined_result = {
            # ê¸°ë³¸ ì •ë³´
            'name': korean_content.get('name', recipe.get('name', 'í–¥ìˆ˜')),
            'description': korean_content.get('description', recipe.get('description', 'íŠ¹ë³„í•œ í–¥ìˆ˜ì…ë‹ˆë‹¤.')),
            
            # ë ˆì‹œí”¼ êµ¬ì„±
            'top_notes': recipe.get('top_notes', []),
            'middle_notes': recipe.get('middle_notes', []),
            'base_notes': recipe.get('base_notes', []),
            'intensity': recipe.get('intensity', 5.0),
            
            # í’ˆì§ˆ ì ìˆ˜ë“¤
            'composition_harmony': recipe.get('composition_harmony', 0.7),
            'confidence_scores': recipe.get('confidence_scores', {}),
            
            # ë”¥ëŸ¬ë‹ ì˜ˆì¸¡ ì •ë³´ (ìˆëŠ” ê²½ìš°)
            'ml_predictions': {
                'predicted_rating': recipe.get('predicted_rating'),
                'predicted_gender': recipe.get('predicted_gender'),
                'gender_probabilities': recipe.get('gender_probabilities', {}),
                'ml_confidence': recipe.get('ml_confidence'),
                'ml_enhanced': recipe.get('ml_enhanced', False)
            },
            
            # í•œêµ­ì–´ ì½˜í…ì¸ 
            'korean_content': {
                'emotional_story': korean_content.get('emotional_story', ''),
                'usage_recommendation': korean_content.get('usage_recommendation', ''),
                'cultural_context': korean_content.get('cultural_context', '')
            },
            
            # AI ì‹œìŠ¤í…œ ì •ë³´
            'ai_insights': {
                'original_emotions': analysis['emotions'],
                'original_keywords': analysis['keywords'],
                'dl_enhanced': bool(self.enhanced_generator and recipe.get('ml_enhanced')),
                'korean_llm_generated': bool(korean_content)
            }
        }
        
        return combined_result
    
    def _assess_generation_quality(self, result: Dict) -> str:
        """ìƒì„± í’ˆì§ˆ í‰ê°€"""
        quality_indicators = [
            len(result.get('top_notes', [])) >= 2,
            len(result.get('middle_notes', [])) >= 2,
            len(result.get('base_notes', [])) >= 1,
            result.get('composition_harmony', 0) > 0.5,
            bool(result.get('description')),
            result.get('ml_predictions', {}).get('ml_enhanced', False),
            result.get('ml_predictions', {}).get('ml_confidence', 0) > 0.6
        ]
        
        quality_score = sum(quality_indicators) / len(quality_indicators)
        
        if quality_score >= 0.8:
            return "ìµœê³ ê¸‰"
        elif quality_score >= 0.65:
            return "ê³ í’ˆì§ˆ"
        elif quality_score >= 0.5:
            return "ì–‘í˜¸"
        else:
            return "ê¸°ë³¸"
    
    def _generate_fallback_recipe(self, text: str) -> Dict[str, Any]:
        """ìµœì¢… í´ë°± ë ˆì‹œí”¼"""
        return {
            'name': 'ê¸°ë³¸ í–¥ìˆ˜',
            'description': f'"{text}"ì—ì„œ ì˜ê°ì„ ë°›ì€ í–¥ìˆ˜ì…ë‹ˆë‹¤.',
            'top_notes': ['bergamot', 'lemon'],
            'middle_notes': ['rose', 'jasmine'],
            'base_notes': ['musk', 'cedar'],
            'intensity': 5.0,
            'system_info': {
                'fallback_mode': True,
                'generation_quality': 'ê¸°ë³¸',
                'deep_learning_enhanced': False
            }
        }
    
    def _save_to_database(self, recipe: Dict, original_text: str) -> int:
        """ë°ì´í„°ë² ì´ìŠ¤ì— ë ˆì‹œí”¼ ì €ì¥"""
        try:
            with get_db_session() as session:
                db_recipe = Recipe(
                    name=recipe.get('name', 'í–¥ìˆ˜'),
                    description=recipe.get('description', ''),
                    top_notes=','.join(recipe.get('top_notes', [])),
                    middle_notes=','.join(recipe.get('middle_notes', [])),
                    base_notes=','.join(recipe.get('base_notes', [])),
                    intensity=recipe.get('intensity', 5.0)
                )
                session.add(db_recipe)
                session.commit()
                return db_recipe.id
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0
    
    def _update_performance_stats(self, processing_time: float, success: bool):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        if success:
            self.performance_stats['successful_generations'] += 1
        
        total = self.performance_stats['total_requests']
        current_avg = self.performance_stats['average_response_time']
        self.performance_stats['average_response_time'] = (
            (current_avg * (total - 1) + processing_time) / total
        )
    
    def get_system_performance_report(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¦¬í¬íŠ¸"""
        
        report = {
            'performance_stats': self.performance_stats.copy(),
            'deep_learning_stats': {
                'dl_available': bool(self.dl_predictor),
                'dl_enhanced_rate': (
                    self.performance_stats['dl_enhanced_generations'] / 
                    max(1, self.performance_stats['total_requests'])
                )
            },
            'system_components': {
                'total_active_components': len(self._get_active_components()),
                'components': self._get_active_components()
            }
        }
        
        # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì •ë³´ ì¶”ê°€
        if self.dl_predictor:
            report['deep_learning_model_info'] = self.dl_predictor.get_model_info()
        
        # ì „ì²´ ì‹œìŠ¤í…œ ê±´ê°•ì„±
        success_rate = (
            self.performance_stats['successful_generations'] / 
            max(1, self.performance_stats['total_requests'])
        )
        
        report['system_health'] = {
            'success_rate': success_rate,
            'average_response_time': self.performance_stats['average_response_time'],
            'status': 'excellent' if success_rate > 0.95 else 'good' if success_rate > 0.8 else 'needs_attention'
        }
        
        return report

def run_enhanced_demo():
    """ë”¥ëŸ¬ë‹ í†µí•© ì‹œìŠ¤í…œ ë°ëª¨"""
    
    print("ğŸ¤– ë”¥ëŸ¬ë‹ í†µí•© í–¥ìˆ˜ AI ì‹œìŠ¤í…œ ë°ëª¨")
    print("=" * 80)
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    init_db()
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    perfume_ai = DeepLearningEnhancedPerfumeAI()
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤
    test_scenarios = [
        {
            'text': "ë´„ë‚  ì•„ì¹¨ ì •ì›ì—ì„œ í”¼ì–´ë‚˜ëŠ” ì¥ë¯¸ì™€ í•¨ê»˜ ëŠë¼ëŠ” í‰ì˜¨í•˜ê³  í–‰ë³µí•œ ìˆœê°„",
            'preferences': {'intensity': 6, 'gender': 'women', 'season': 'spring'},
            'description': "ğŸŒ¸ ë´„ë‚  ì¥ë¯¸ ì •ì› ì‹œë‚˜ë¦¬ì˜¤"
        },
        {
            'text': "ê²¨ìš¸ ì €ë… ë²½ë‚œë¡œ ì•ì—ì„œ ìœ„ìŠ¤í‚¤ë¥¼ ë§ˆì‹œë©° ëŠë¼ëŠ” ë”°ëœ»í•˜ê³  ê¹Šì´ ìˆëŠ” ê°ì •",
            'preferences': {'intensity': 8, 'gender': 'men', 'season': 'winter'},
            'description': "ğŸ”¥ ê²¨ìš¸ ë²½ë‚œë¡œ ì‹œë‚˜ë¦¬ì˜¤"
        },
        {
            'text': "ì—¬ë¦„ ë°”ë‹¤ì—ì„œ íŒŒë„ ì†Œë¦¬ë¥¼ ë“¤ìœ¼ë©° ëŠë¼ëŠ” ììœ ë¡­ê³  ìƒì¾Œí•œ ê¸°ë¶„",
            'preferences': {'intensity': 5, 'gender': 'unisex', 'season': 'summer'},
            'description': "ğŸŒŠ ì—¬ë¦„ ë°”ë‹¤ ì‹œë‚˜ë¦¬ì˜¤"
        }
    ]
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ¯ í…ŒìŠ¤íŠ¸ {i}: {scenario['description']}")
        print(f"ğŸ“ ì…ë ¥: {scenario['text']}")
        print(f"ğŸ‘¤ ì„ í˜¸ë„: {scenario['preferences']}")
        print("-" * 60)
        
        # ë”¥ëŸ¬ë‹ í†µí•© ë ˆì‹œí”¼ ìƒì„±
        result = perfume_ai.generate_perfume_with_deep_learning(
            text=scenario['text'],
            user_preferences=scenario['preferences'],
            use_rag=True,
            generate_korean_content=True
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"âœ¨ í–¥ìˆ˜ëª…: {result['name']}")
        print(f"ğŸ“– ì„¤ëª…: {result['description']}")
        print(f"ğŸ¼ êµ¬ì„±:")
        print(f"   â€¢ íƒ‘ ë…¸íŠ¸: {', '.join(result['top_notes'])}")
        print(f"   â€¢ ë¯¸ë“¤ ë…¸íŠ¸: {', '.join(result['middle_notes'])}")
        print(f"   â€¢ ë² ì´ìŠ¤ ë…¸íŠ¸: {', '.join(result['base_notes'])}")
        print(f"ğŸ’ª ê°•ë„: {result['intensity']:.1f}/10")
        
        # ë”¥ëŸ¬ë‹ ì˜ˆì¸¡ ì •ë³´
        ml_pred = result.get('ml_predictions', {})
        if ml_pred.get('ml_enhanced'):
            print(f"ğŸ¤– AI ì˜ˆì¸¡ í‰ì : {ml_pred.get('predicted_rating', 'N/A'):.2f}/5.0")
            print(f"ğŸ‘¥ ì˜ˆì¸¡ ì„±ë³„: {ml_pred.get('predicted_gender', 'N/A')}")
            print(f"ğŸ¯ ML ì‹ ë¢°ë„: {ml_pred.get('ml_confidence', 0):.1%}")
        
        # ì‹œìŠ¤í…œ ì •ë³´
        system_info = result.get('system_info', {})
        print(f"ğŸ”§ ë”¥ëŸ¬ë‹ ê°•í™”: {'âœ…' if system_info.get('deep_learning_enhanced') else 'âŒ'}")
        print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result.get('processing_time', 0):.2f}ì´ˆ")
        print(f"â­ ìƒì„± í’ˆì§ˆ: {system_info.get('generation_quality', 'unknown')}")
    
    # ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¦¬í¬íŠ¸
    print(f"\n{'='*80}")
    print("ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¦¬í¬íŠ¸")
    print("=" * 80)
    
    performance_report = perfume_ai.get_system_performance_report()
    
    print(f"ğŸ“ˆ ì´ ìš”ì²­ ìˆ˜: {performance_report['performance_stats']['total_requests']}")
    print(f"âœ… ì„±ê³µ ìƒì„±: {performance_report['performance_stats']['successful_generations']}")
    print(f"ğŸ¤– ë”¥ëŸ¬ë‹ ê°•í™”ìœ¨: {performance_report['deep_learning_stats']['dl_enhanced_rate']:.1%}")
    print(f"âš¡ í‰ê·  ì‘ë‹µ ì‹œê°„: {performance_report['performance_stats']['average_response_time']:.2f}ì´ˆ")
    print(f"ğŸ¥ ì‹œìŠ¤í…œ ìƒíƒœ: {performance_report['system_health']['status']}")
    print(f"ğŸ’¯ ì„±ê³µë¥ : {performance_report['system_health']['success_rate']:.1%}")
    
    active_components = performance_report['system_components']['components']
    print(f"ğŸ”§ í™œì„± ì»´í¬ë„ŒíŠ¸ ({len(active_components)}ê°œ):")
    for component in active_components:
        print(f"   â€¢ {component}")
    
    print("\nğŸ‰ ë”¥ëŸ¬ë‹ í†µí•© í–¥ìˆ˜ AI ì‹œìŠ¤í…œ ë°ëª¨ ì™„ë£Œ!")

if __name__ == "__main__":
    try:
        run_enhanced_demo()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ë°ëª¨ê°€ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ë°ëª¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()