#!/usr/bin/env python3
"""
ê³ ì‹ ë¢°ë„ ì˜í™” í–¥ë£Œ AI ëª¨ë¸ í›ˆë ¨ê¸° (90% ì´ìƒ ëª©í‘œ)
ê°œì„ ëœ íŠ¹ì„± ì¶”ì¶œ, ëª¨ë¸ ì•„í‚¤í…ì²˜, ì•™ìƒë¸” ê¸°ë²• ì ìš©
"""

import sys
import json
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Any
import logging
from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import accuracy_score, classification_report, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
import joblib
import re

# PyTorch ì„í¬íŠ¸
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau

# ìƒìœ„ ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedMovieScentDataset(Dataset):
    """í–¥ìƒëœ ì˜í™” ì¥ë©´-í–¥ë£Œ ë°ì´í„°ì…‹"""
    
    def __init__(self, features: np.ndarray, targets: Dict[str, np.ndarray], augment: bool = False):
        self.features = torch.FloatTensor(features)
        self.targets = {key: torch.FloatTensor(val) for key, val in targets.items()}
        self.augment = augment
    
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        features = self.features[idx]
        targets = {key: val[idx] for key, val in self.targets.items()}
        
        # ë°ì´í„° ì¦ê°• (í›ˆë ¨ ì‹œ)
        if self.augment and torch.rand(1) < 0.3:
            # ë…¸ì´ì¦ˆ ì¶”ê°€ (5% ë²”ìœ„)
            noise = torch.randn_like(features) * 0.05
            features = features + noise
            features = torch.clamp(features, -3, 3)  # ì •ê·œí™” ë²”ìœ„ ë‚´ ìœ ì§€
        
        return {'features': features, 'targets': targets}

class AttentionBlock(nn.Module):
    """ì–´í…ì…˜ ë¸”ë¡"""
    
    def __init__(self, input_dim: int, output_dim: int = 256):
        super().__init__()
        self.output_dim = output_dim
        self.attention = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, output_dim),
            nn.Tanh()
        )
        
    def forward(self, x):
        # x: [batch_size, input_dim]
        attended = self.attention(x)  # [batch_size, output_dim]
        return attended, torch.ones(x.size(0), 1)  # ë”ë¯¸ ì–´í…ì…˜ ê°€ì¤‘ì¹˜

class EnhancedMovieScentNeuralNetwork(nn.Module):
    """í–¥ìƒëœ ì˜í™” ì¥ë©´ ê¸°ë°˜ í–¥ë£Œ ì¶”ì²œ ì‹ ê²½ë§"""
    
    def __init__(self, input_dim: int, material_count: int, emotion_count: int):
        super().__init__()
        
        self.input_dim = input_dim
        self.material_count = material_count
        self.emotion_count = emotion_count
        
        # 1. ì…ë ¥ ì„ë² ë”©ì¸µ
        self.input_embedding = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # 2. ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
        self.attention = AttentionBlock(256, 256)
        
        # 3. íŠ¹ì„± ì¶”ì¶œ ë°±ë³¸ (ResNet ìŠ¤íƒ€ì¼)
        self.backbone = nn.ModuleList([
            self._make_residual_block(256, 256),
            self._make_residual_block(256, 512),
            self._make_residual_block(512, 512),
            self._make_residual_block(512, 256)
        ])
        
        # 4. ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì„± ìœµí•©
        self.feature_fusion = nn.Sequential(
            nn.Linear(256 + 256, 512),  # ë°±ë³¸ + ì–´í…ì…˜ (ë‘˜ ë‹¤ 256ì°¨ì›)
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.3),
            
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.2)
        )
        
        # 5. ì „ë¬¸í™”ëœ ì¶œë ¥ í—¤ë“œë“¤
        # ì¬ë£Œ ë†ë„ ì˜ˆì¸¡ (ë‹¤ì¸µ íšŒê·€)
        self.material_head = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.1),
            
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, material_count),
            nn.Sigmoid()
        )
        
        # íœ˜ë°œì„± ë ˆë²¨ ì˜ˆì¸¡ (ë¶„ë¥˜)
        self.volatility_head = nn.Sequential(
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 3)
        )
        
        # ì§€ì†ì‹œê°„ ì˜ˆì¸¡ (íšŒê·€)
        self.duration_head = nn.Sequential(
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.ReLU()
        )
        
        # ê°ì • ì˜ˆì¸¡ (ë‹¤ì¤‘ ë¼ë²¨)
        self.emotion_head = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.1),
            
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, emotion_count),
            nn.Sigmoid()
        )
        
        # ì˜ˆì¸¡ ì‹ ë¢°ë„ í—¤ë“œ
        self.confidence_head = nn.Sequential(
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self.apply(self._init_weights)
    
    def _make_residual_block(self, input_dim: int, output_dim: int):
        """ì”ì°¨ ë¸”ë¡ ìƒì„±"""
        if input_dim != output_dim:
            return nn.Sequential(
                nn.Linear(input_dim, output_dim),
                nn.BatchNorm1d(output_dim),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(output_dim, output_dim),
                nn.BatchNorm1d(output_dim),
            )
        else:
            return nn.Sequential(
                nn.Linear(input_dim, output_dim),
                nn.BatchNorm1d(output_dim),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(output_dim, output_dim),
                nn.BatchNorm1d(output_dim),
            )
    
    def _init_weights(self, module):
        """ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        if isinstance(module, nn.Linear):
            torch.nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                torch.nn.init.constant_(module.bias, 0)
        elif isinstance(module, nn.BatchNorm1d):
            torch.nn.init.constant_(module.weight, 1)
            torch.nn.init.constant_(module.bias, 0)
    
    def forward(self, x):
        # 1. ì…ë ¥ ì„ë² ë”©
        embedded = self.input_embedding(x)
        
        # 2. ì–´í…ì…˜ ì ìš©
        attended, attention_weights = self.attention(embedded)
        
        # 3. ë°±ë³¸ í†µê³¼ (ì”ì°¨ ì—°ê²°)
        features = embedded
        for block in self.backbone:
            residual = features
            features = block(features)
            if features.shape == residual.shape:
                features = features + residual  # ì”ì°¨ ì—°ê²°
            features = F.relu(features)
        
        # 4. íŠ¹ì„± ìœµí•©
        fused_features = torch.cat([features, attended], dim=1)
        final_features = self.feature_fusion(fused_features)
        
        # 5. ë‹¤ì¤‘ ì¶œë ¥
        outputs = {
            'materials': self.material_head(final_features),
            'volatility': self.volatility_head(final_features),
            'duration': self.duration_head(final_features),
            'emotions': self.emotion_head(final_features),
            'confidence': self.confidence_head(final_features)
        }
        
        return outputs, attention_weights

class EnhancedMovieScentTrainer:
    """í–¥ìƒëœ ì˜í™” í–¥ë£Œ ëª¨ë¸ í›ˆë ¨ê¸°"""
    
    def __init__(self, data_path: str = "generated_recipes/all_movie_recipes.json"):
        self.data_path = Path(data_path)
        self.model_save_dir = Path("models/enhanced_movie_scent_models")
        self.model_save_dir.mkdir(parents=True, exist_ok=True)
        
        # í–¥ìƒëœ ì „ì²˜ë¦¬ ë„êµ¬ë“¤
        self.feature_scaler = RobustScaler()  # ì´ìƒì¹˜ì— ë” ê²¬ê³ 
        self.label_encoders = {}
        self.material_vocab = {}
        self.emotion_vocab = {}
        
        # ì•™ìƒë¸” ëª¨ë¸ë“¤
        self.models = []
        self.rf_model = None  # ë°±ì—… ëœë¤í¬ë ˆìŠ¤íŠ¸
        
        # í›ˆë ¨ íˆìŠ¤í† ë¦¬
        self.training_history = {
            'train_loss': [],
            'val_loss': [],
            'confidence_scores': []
        }
        
    def extract_advanced_features(self, recipe: Dict) -> List[float]:
        """ê³ ê¸‰ íŠ¹ì„± ì¶”ì¶œ (ê¸°ì¡´ë³´ë‹¤ ë” ìƒì„¸)"""
        scene_desc = recipe['scene_description']
        metadata = recipe['metadata']
        
        features = []
        
        # 1. ì¥ë¥´ ì›-í•« ì¸ì½”ë”© (7ê°œ)
        genres = ['action', 'romantic', 'horror', 'drama', 'thriller', 'comedy', 'sci_fi']
        genre_vector = [1.0 if metadata['genre'] == genre else 0.0 for genre in genres]
        features.extend(genre_vector)
        
        # 2. í–¥ìƒëœ í…ìŠ¤íŠ¸ íŠ¹ì„±
        text_features = self._extract_advanced_text_features(scene_desc)
        features.extend(text_features)
        
        # 3. ì˜í™”ë³„ íŠ¹ì„±
        movie_features = self._extract_movie_specific_features(metadata['movie_title'])
        features.extend(movie_features)
        
        # 4. ì‹œê°„ì  íŠ¹ì„±
        temporal_features = self._extract_temporal_features(scene_desc)
        features.extend(temporal_features)
        
        # 5. ê°ì • ê°•ë„ íŠ¹ì„±
        emotion_features = self._extract_emotion_intensity_features(scene_desc)
        features.extend(emotion_features)
        
        return features
    
    def _extract_advanced_text_features(self, text: str) -> List[float]:
        """ê³ ê¸‰ í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ì¶œ"""
        text_lower = text.lower()
        
        # ì„¸ë¶„í™”ëœ í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬
        advanced_keywords = {
            # ì•¡ì…˜ ì„¸ë¶€ ë¶„ë¥˜
            'explosion': ['explosion', 'blast', 'bomb', 'fire', 'flame'],
            'vehicle': ['car', 'bike', 'truck', 'helicopter', 'plane'],
            'weapon': ['gun', 'sword', 'knife', 'fight', 'battle'],
            'chase': ['chase', 'run', 'pursuit', 'escape'],
            
            # ë¡œë§¨ìŠ¤ ì„¸ë¶€ ë¶„ë¥˜
            'intimacy': ['kiss', 'embrace', 'touch', 'caress'],
            'romance_setting': ['beach', 'sunset', 'garden', 'candlelight'],
            'emotion_love': ['love', 'heart', 'romantic', 'tender'],
            
            # ê³µí¬ ì„¸ë¶€ ë¶„ë¥˜
            'darkness': ['dark', 'shadow', 'night', 'black'],
            'fear_objects': ['blood', 'ghost', 'monster', 'demon'],
            'scary_places': ['basement', 'attic', 'cemetery', 'forest'],
            
            # ìì—° í™˜ê²½
            'water': ['ocean', 'sea', 'rain', 'river', 'lake'],
            'earth': ['mountain', 'desert', 'field', 'ground'],
            'air': ['wind', 'breeze', 'sky', 'cloud'],
            'vegetation': ['flower', 'tree', 'grass', 'forest'],
            
            # ë„ì‹œ í™˜ê²½
            'indoor': ['room', 'house', 'building', 'office'],
            'outdoor': ['street', 'park', 'square', 'road'],
            'transport': ['station', 'airport', 'port', 'terminal'],
            
            # ì‹œê°„ í‘œí˜„
            'morning': ['morning', 'dawn', 'sunrise', 'early'],
            'day': ['day', 'noon', 'afternoon', 'bright'],
            'evening': ['evening', 'sunset', 'dusk', 'twilight'],
            'night': ['night', 'midnight', 'late', 'darkness'],
            
            # ê°ì • ê°•ë„
            'high_intensity': ['intense', 'extreme', 'massive', 'huge'],
            'medium_intensity': ['strong', 'powerful', 'significant'],
            'low_intensity': ['gentle', 'soft', 'quiet', 'subtle']
        }
        
        features = []
        for category, keywords in advanced_keywords.items():
            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ (ì •ê·œí™”)
            matches = sum(1 for keyword in keywords if keyword in text_lower)
            score = matches / len(keywords)
            features.append(score)
            
            # í‚¤ì›Œë“œ ìœ„ì¹˜ ê°€ì¤‘ì¹˜ (ë¬¸ì¥ ì•ë¶€ë¶„ì¼ìˆ˜ë¡ ì¤‘ìš”)
            position_weight = 0.0
            for keyword in keywords:
                pos = text_lower.find(keyword)
                if pos != -1:
                    position_weight += (len(text_lower) - pos) / len(text_lower)
            features.append(position_weight / max(1, len(keywords)))
        
        # ë¬¸ì¥ êµ¬ì¡° íŠ¹ì„±
        words = text.split()
        features.extend([
            len(words) / 50.0,  # ì •ê·œí™”ëœ ë‹¨ì–´ ìˆ˜
            len([w for w in words if len(w) > 6]) / max(1, len(words)),  # ê¸´ ë‹¨ì–´ ë¹„ìœ¨
            len([w for w in words if w.isupper()]) / max(1, len(words)),  # ëŒ€ë¬¸ì ë¹„ìœ¨
            text.count(',') / max(1, len(words)),  # ì½¤ë§ˆ ë°€ë„
            text.count('.') / max(1, len(words)),  # ë§ˆì¹¨í‘œ ë°€ë„
        ])
        
        return features
    
    def _extract_movie_specific_features(self, movie_title: str) -> List[float]:
        """ì˜í™”ë³„ íŠ¹ì„± ì¶”ì¶œ"""
        # ì˜í™” ë©”íƒ€ ì •ë³´ (ì¶œì‹œë…„ë„, í‰ì , ì¥ë¥´ í˜¼í•© ë“±)
        movie_metadata = {
            'Mad Max Fury Road': [2015, 8.1, 1.0, 0.0],  # [year, rating, action_weight, romance_weight]
            'John Wick': [2014, 7.4, 1.0, 0.0],
            'Titanic': [1997, 7.8, 0.2, 1.0],
            'The Notebook': [2004, 7.8, 0.0, 1.0],
            'The Shining': [1980, 8.4, 0.1, 0.0],
            'The Godfather': [1972, 9.2, 0.3, 0.1],
            # ... ë” ì¶”ê°€ ê°€ëŠ¥
        }
        
        if movie_title in movie_metadata:
            metadata = movie_metadata[movie_title]
            # ì •ê·œí™”
            features = [
                (metadata[0] - 1970) / 50.0,  # ì—°ë„ ì •ê·œí™”
                metadata[1] / 10.0,  # í‰ì  ì •ê·œí™”
                metadata[2],  # ì•¡ì…˜ ê°€ì¤‘ì¹˜
                metadata[3]   # ë¡œë§¨ìŠ¤ ê°€ì¤‘ì¹˜
            ]
        else:
            features = [0.5, 0.7, 0.5, 0.5]  # ê¸°ë³¸ê°’
        
        return features
    
    def _extract_temporal_features(self, text: str) -> List[float]:
        """ì‹œê°„ì  íŠ¹ì„± ì¶”ì¶œ"""
        text_lower = text.lower()
        
        time_patterns = {
            'specific_times': r'\b(\d{1,2}:\d{2}|\d{1,2}ì‹œ|\d{1,2}am|\d{1,2}pm)\b',
            'duration': r'\b(\d+ë¶„|\d+ì´ˆ|\d+ì‹œê°„|\d+ minutes|\d+ seconds|\d+ hours)\b',
            'temporal_sequence': ['first', 'then', 'next', 'finally', 'meanwhile', 'suddenly'],
            'speed_indicators': ['fast', 'slow', 'quick', 'gradual', 'instant', 'immediate']
        }
        
        features = []
        
        # êµ¬ì²´ì  ì‹œê°„ ì–¸ê¸‰
        features.append(1.0 if re.search(time_patterns['specific_times'], text_lower) else 0.0)
        
        # ì§€ì†ì‹œê°„ ì–¸ê¸‰
        features.append(1.0 if re.search(time_patterns['duration'], text_lower) else 0.0)
        
        # ì‹œê°„ì  ìˆœì„œ í‘œí˜„
        sequence_score = sum(1 for seq in time_patterns['temporal_sequence'] if seq in text_lower)
        features.append(min(1.0, sequence_score / 3.0))
        
        # ì†ë„ í‘œí˜„
        speed_score = sum(1 for speed in time_patterns['speed_indicators'] if speed in text_lower)
        features.append(min(1.0, speed_score / 2.0))
        
        return features
    
    def _extract_emotion_intensity_features(self, text: str) -> List[float]:
        """ê°ì • ê°•ë„ íŠ¹ì„± ì¶”ì¶œ"""
        text_lower = text.lower()
        
        # ê°ì • ê°•ë„ í‚¤ì›Œë“œ
        intensity_levels = {
            'extreme': ['extreme', 'ultimate', 'maximum', 'overwhelming', 'devastating'],
            'very_high': ['intense', 'powerful', 'strong', 'dramatic', 'incredible'],
            'high': ['significant', 'notable', 'important', 'serious', 'major'],
            'medium': ['moderate', 'regular', 'normal', 'typical', 'standard'],
            'low': ['mild', 'gentle', 'soft', 'light', 'subtle'],
            'minimal': ['barely', 'hardly', 'slight', 'minor', 'weak']
        }
        
        features = []
        for level, keywords in intensity_levels.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            features.append(min(1.0, score / len(keywords)))
        
        # ê°ì • ìˆ˜ì‹ì–´ ë¶„ì„
        emotion_modifiers = ['very', 'extremely', 'incredibly', 'absolutely', 'completely']
        modifier_score = sum(1 for mod in emotion_modifiers if mod in text_lower)
        features.append(min(1.0, modifier_score / 3.0))
        
        return features
    
    def load_and_preprocess_enhanced_data(self) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:
        """í–¥ìƒëœ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        logger.info(f"Loading enhanced data from {self.data_path}")
        
        with open(self.data_path, 'r', encoding='utf-8') as f:
            recipes = json.load(f)
        
        logger.info(f"Loaded {len(recipes):,} recipes")
        
        # ë°ì´í„° í’ˆì§ˆ í•„í„°ë§
        filtered_recipes = []
        for recipe in recipes:
            # í’ˆì§ˆ ê²€ì‚¬
            if self._is_high_quality_recipe(recipe):
                filtered_recipes.append(recipe)
        
        logger.info(f"Filtered to {len(filtered_recipes):,} high-quality recipes")
        recipes = filtered_recipes
        
        # ì–´íœ˜ì§‘ êµ¬ì¶•
        all_materials = set()
        all_emotions = set()
        
        for recipe in recipes:
            for note_type in ['top_notes', 'middle_notes', 'base_notes']:
                for note in recipe['fragrance_notes'][note_type]:
                    all_materials.add(note['name'])
            all_emotions.update(recipe['detected_emotions'])
        
        self.material_vocab = {material: idx for idx, material in enumerate(sorted(all_materials))}
        self.emotion_vocab = {emotion: idx for idx, emotion in enumerate(sorted(all_emotions))}
        
        logger.info(f"Enhanced vocabulary - Materials: {len(self.material_vocab)}, Emotions: {len(self.emotion_vocab)}")
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ì¶”ì¶œ
        features = []
        material_targets = []
        volatility_targets = []
        duration_targets = []
        emotion_targets = []
        confidence_targets = []  # ì‹ ë¢°ë„ íƒ€ê²Ÿ
        
        for recipe in recipes:
            # 1. í–¥ìƒëœ íŠ¹ì„± ë²¡í„°
            scene_features = self.extract_advanced_features(recipe)
            features.append(scene_features)
            
            # 2. íƒ€ê²Ÿë“¤ (ê¸°ì¡´ê³¼ ë™ì¼í•˜ì§€ë§Œ í’ˆì§ˆ ê°€ì¤‘ì¹˜ ì¶”ê°€)
            material_vector = self._extract_material_concentrations(recipe)
            material_targets.append(material_vector)
            
            volatility_level = self._encode_volatility(recipe['volatility_level'])
            volatility_targets.append(volatility_level)
            
            duration = self._extract_duration_seconds(recipe['duration_estimate'])
            duration_targets.append(duration)
            
            emotion_vector = self._encode_emotions(recipe['detected_emotions'])
            emotion_targets.append(emotion_vector)
            
            # 3. ì‹ ë¢°ë„ íƒ€ê²Ÿ (ë°ì´í„° í’ˆì§ˆ ê¸°ë°˜)
            confidence_score = self._calculate_recipe_quality_score(recipe)
            confidence_targets.append(confidence_score)
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        X = np.array(features)
        y = {
            'materials': np.array(material_targets),
            'volatility': np.array(volatility_targets),
            'duration': np.array(duration_targets).reshape(-1, 1),
            'emotions': np.array(emotion_targets),
            'confidence': np.array(confidence_targets).reshape(-1, 1)
        }
        
        logger.info(f"Enhanced feature shape: {X.shape}")
        logger.info(f"Feature count: {X.shape[1]} (vs original 16)")
        
        # ê°•ê±´í•œ ì •ê·œí™”
        X = self.feature_scaler.fit_transform(X)
        
        return X, y
    
    def _is_high_quality_recipe(self, recipe: Dict) -> bool:
        """ë ˆì‹œí”¼ í’ˆì§ˆ ê²€ì‚¬"""
        try:
            # 1. í•„ìˆ˜ í•„ë“œ ì¡´ì¬ í™•ì¸
            required_fields = ['scene_description', 'volatility_level', 'fragrance_notes', 'detected_emotions']
            for field in required_fields:
                if field not in recipe:
                    return False
            
            # 2. ì¥ë©´ ì„¤ëª… ê¸¸ì´ ì²´í¬
            if len(recipe['scene_description']) < 20:
                return False
            
            # 3. í–¥ë£Œ ë…¸íŠ¸ ê°œìˆ˜ ì²´í¬
            total_notes = (len(recipe['fragrance_notes']['top_notes']) + 
                          len(recipe['fragrance_notes']['middle_notes']) + 
                          len(recipe['fragrance_notes']['base_notes']))
            if total_notes < 3:
                return False
            
            # 4. ë†ë„ í•©ê³„ ì²´í¬
            total_concentration = 0
            for note_type in ['top_notes', 'middle_notes', 'base_notes']:
                for note in recipe['fragrance_notes'][note_type]:
                    if 'concentration_percent' in note:
                        total_concentration += note['concentration_percent']
            
            if total_concentration < 5 or total_concentration > 50:  # 5-50% ë²”ìœ„
                return False
            
            return True
        except:
            return False
    
    def _calculate_recipe_quality_score(self, recipe: Dict) -> float:
        """ë ˆì‹œí”¼ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0.5-1.0)"""
        score = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # ì¥ë©´ ì„¤ëª… í’ˆì§ˆ (+0.2)
        desc_len = len(recipe['scene_description'])
        if desc_len > 50:
            score += 0.1
        if desc_len > 100:
            score += 0.1
        
        # í–¥ë£Œ ë‹¤ì–‘ì„± (+0.2)
        total_notes = (len(recipe['fragrance_notes']['top_notes']) + 
                      len(recipe['fragrance_notes']['middle_notes']) + 
                      len(recipe['fragrance_notes']['base_notes']))
        if total_notes >= 5:
            score += 0.1
        if total_notes >= 8:
            score += 0.1
        
        # ê°ì • ë‹¤ì–‘ì„± (+0.1)
        if len(recipe['detected_emotions']) > 1:
            score += 0.1
        
        return min(1.0, score)
    
    def _extract_material_concentrations(self, recipe: Dict) -> List[float]:
        """ì›ë£Œë³„ ë†ë„ ë²¡í„° ì¶”ì¶œ (ë™ì¼)"""
        concentrations = [0.0] * len(self.material_vocab)
        
        for note_type in ['top_notes', 'middle_notes', 'base_notes']:
            for note in recipe['fragrance_notes'][note_type]:
                material_name = note['name']
                if material_name in self.material_vocab:
                    idx = self.material_vocab[material_name]
                    concentrations[idx] = float(note['concentration_percent']) / 100.0
        
        return concentrations
    
    def _encode_volatility(self, volatility_level: str) -> int:
        """íœ˜ë°œì„± ë ˆë²¨ ì¸ì½”ë”© (ë™ì¼)"""
        volatility_map = {
            'low_volatility': 0,
            'medium_volatility': 1,
            'high_volatility': 2
        }
        return volatility_map.get(volatility_level, 1)
    
    def _extract_duration_seconds(self, duration_str: str) -> float:
        """ì§€ì†ì‹œê°„ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜ (ë™ì¼)"""
        if '10-30ì´ˆ' in duration_str:
            return 20.0
        elif '1-2ë¶„' in duration_str:
            return 90.0
        elif '2-5ë¶„' in duration_str:
            return 210.0
        elif '5-10ë¶„' in duration_str:
            return 450.0
        else:
            return 120.0
    
    def _encode_emotions(self, emotions: List[str]) -> List[float]:
        """ê°ì • ë‹¤ì¤‘ ë¼ë²¨ ì¸ì½”ë”© (ë™ì¼)"""
        emotion_vector = [0.0] * len(self.emotion_vocab)
        for emotion in emotions:
            if emotion in self.emotion_vocab:
                idx = self.emotion_vocab[emotion]
                emotion_vector[idx] = 1.0
        return emotion_vector
    
    def create_enhanced_data_loaders(self, X: np.ndarray, y: Dict[str, np.ndarray], 
                                   batch_size: int = 32, test_size: float = 0.15):
        """í–¥ìƒëœ ë°ì´í„° ë¡œë” ìƒì„±"""
        # ì¸µí™” ë¶„í•  (ì¥ë¥´ë³„ ê· ë“±í•˜ê²Œ)
        indices = np.arange(len(X))
        train_idx, val_idx = train_test_split(indices, test_size=test_size, 
                                            random_state=42, shuffle=True)
        
        X_train, X_val = X[train_idx], X[val_idx]
        y_train = {key: val[train_idx] for key, val in y.items()}
        y_val = {key: val[val_idx] for key, val in y.items()}
        
        # ë°ì´í„°ì…‹ ìƒì„± (í›ˆë ¨ ì‹œì—ë§Œ ì¦ê°•)
        train_dataset = EnhancedMovieScentDataset(X_train, y_train, augment=True)
        val_dataset = EnhancedMovieScentDataset(X_val, y_val, augment=False)
        
        # ë°ì´í„° ë¡œë” ìƒì„±
        train_loader = DataLoader(train_dataset, batch_size=batch_size, 
                                shuffle=True, num_workers=0, drop_last=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, 
                              shuffle=False, num_workers=0)
        
        logger.info(f"Enhanced data loaders - Train: {len(train_dataset)}, Val: {len(val_dataset)}")
        
        return train_loader, val_loader
    
    def create_enhanced_model(self, input_dim: int):
        """í–¥ìƒëœ ëª¨ë¸ ìƒì„±"""
        material_count = len(self.material_vocab)
        emotion_count = len(self.emotion_vocab)
        
        model = EnhancedMovieScentNeuralNetwork(
            input_dim=input_dim,
            material_count=material_count,
            emotion_count=emotion_count
        )
        
        logger.info(f"Enhanced model created with {input_dim} input features")
        logger.info(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
        
        return model
    
    def train_enhanced_model(self, train_loader, val_loader, epochs: int = 300):
        """í–¥ìƒëœ ëª¨ë¸ í›ˆë ¨"""
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"Training on device: {device}")
        
        model = self.create_enhanced_model(train_loader.dataset.features.shape[1])
        model.to(device)
        
        # ì†ì‹¤ í•¨ìˆ˜ë“¤ (ê°€ì¤‘ì¹˜ ì¡°ì •)
        material_criterion = nn.MSELoss()
        volatility_criterion = nn.CrossEntropyLoss()
        duration_criterion = nn.MSELoss()
        emotion_criterion = nn.BCELoss()
        confidence_criterion = nn.MSELoss()
        
        # ìµœì í™”ê¸° (í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§)
        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
        scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)
        
        best_val_loss = float('inf')
        patience = 30
        patience_counter = 0
        
        for epoch in range(epochs):
            # í›ˆë ¨
            model.train()
            train_losses = []
            train_confidences = []
            
            for batch in train_loader:
                features = batch['features'].to(device)
                targets = {key: val.to(device) for key, val in batch['targets'].items()}
                
                optimizer.zero_grad()
                
                outputs, attention_weights = model(features)
                
                # ê° ì†ì‹¤ ê³„ì‚°
                material_loss = material_criterion(outputs['materials'], targets['materials'])
                volatility_loss = volatility_criterion(outputs['volatility'], targets['volatility'].long())
                duration_loss = duration_criterion(outputs['duration'], targets['duration'])
                emotion_loss = emotion_criterion(outputs['emotions'], targets['emotions'])
                confidence_loss = confidence_criterion(outputs['confidence'], targets['confidence'])
                
                # ì´ ì†ì‹¤ (ê°€ì¤‘ì¹˜ ìµœì í™”)
                total_loss = (
                    3.0 * material_loss +      # ì›ë£Œ ì¡°í•©ì´ ê°€ì¥ ì¤‘ìš”
                    1.5 * volatility_loss +    # íœ˜ë°œì„±ë„ ì¤‘ìš”
                    1.0 * duration_loss +      # ì§€ì†ì‹œê°„
                    1.2 * emotion_loss +       # ê°ì • ì¼ì¹˜ë„
                    2.0 * confidence_loss      # ì‹ ë¢°ë„ ì˜ˆì¸¡
                )
                
                total_loss.backward()
                
                # ê·¸ë¼ë””ì–¸íŠ¸ í´ë¦¬í•‘
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                train_losses.append(total_loss.item())
                train_confidences.extend(outputs['confidence'].cpu().detach().numpy())
            
            # ê²€ì¦
            model.eval()
            val_losses = []
            val_confidences = []
            
            with torch.no_grad():
                for batch in val_loader:
                    features = batch['features'].to(device)
                    targets = {key: val.to(device) for key, val in batch['targets'].items()}
                    
                    outputs, _ = model(features)
                    
                    material_loss = material_criterion(outputs['materials'], targets['materials'])
                    volatility_loss = volatility_criterion(outputs['volatility'], targets['volatility'].long())
                    duration_loss = duration_criterion(outputs['duration'], targets['duration'])
                    emotion_loss = emotion_criterion(outputs['emotions'], targets['emotions'])
                    confidence_loss = confidence_criterion(outputs['confidence'], targets['confidence'])
                    
                    total_loss = (
                        3.0 * material_loss +
                        1.5 * volatility_loss +
                        1.0 * duration_loss +
                        1.2 * emotion_loss +
                        2.0 * confidence_loss
                    )
                    
                    val_losses.append(total_loss.item())
                    val_confidences.extend(outputs['confidence'].cpu().detach().numpy())
            
            avg_train_loss = np.mean(train_losses)
            avg_val_loss = np.mean(val_losses)
            avg_train_confidence = np.mean(train_confidences)
            avg_val_confidence = np.mean(val_confidences)
            
            scheduler.step()
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            self.training_history['train_loss'].append(avg_train_loss)
            self.training_history['val_loss'].append(avg_val_loss)
            self.training_history['confidence_scores'].append(avg_val_confidence)
            
            if epoch % 20 == 0:
                logger.info(f"Epoch {epoch:3d}: Train Loss = {avg_train_loss:.4f}, "
                          f"Val Loss = {avg_val_loss:.4f}, "
                          f"Val Confidence = {avg_val_confidence:.3f}")
            
            # ì¡°ê¸° ì¢…ë£Œ ë° ëª¨ë¸ ì €ì¥
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                patience_counter = 0
                self.save_enhanced_model(model, epoch, avg_val_confidence)
            else:
                patience_counter += 1
            
            if patience_counter >= patience:
                logger.info(f"Early stopping at epoch {epoch}")
                break
        
        logger.info(f"Training completed! Best validation loss: {best_val_loss:.4f}")
        return model
    
    def save_enhanced_model(self, model, epoch: int, confidence: float):
        """í–¥ìƒëœ ëª¨ë¸ ì €ì¥"""
        # ëª¨ë¸ ì €ì¥
        model_path = self.model_save_dir / f"enhanced_movie_scent_model_conf_{confidence:.3f}.pth"
        torch.save({
            'model_state_dict': model.state_dict(),
            'model_config': {
                'input_dim': model.input_dim,
                'material_count': model.material_count,
                'emotion_count': model.emotion_count
            },
            'epoch': epoch,
            'confidence': confidence,
            'training_history': self.training_history
        }, model_path)
        
        # ì „ì²˜ë¦¬ê¸°ë“¤ ì €ì¥
        preprocessor_path = self.model_save_dir / "enhanced_preprocessors.pkl"
        joblib.dump({
            'feature_scaler': self.feature_scaler,
            'material_vocab': self.material_vocab,
            'emotion_vocab': self.emotion_vocab,
            'label_encoders': self.label_encoders
        }, preprocessor_path)
        
        logger.info(f"Enhanced model saved: confidence = {confidence:.3f}")
    
    def run_enhanced_training_pipeline(self):
        """í–¥ìƒëœ ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("Starting enhanced training pipeline for 90%+ confidence...")
        
        # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        X, y = self.load_and_preprocess_enhanced_data()
        
        # 2. ë°ì´í„° ë¡œë” ìƒì„±
        train_loader, val_loader = self.create_enhanced_data_loaders(X, y, batch_size=32)
        
        # 3. ëª¨ë¸ í›ˆë ¨
        model = self.train_enhanced_model(train_loader, val_loader, epochs=300)
        
        logger.info("Enhanced training pipeline completed!")
        
        # 4. ìµœì¢… ì„±ëŠ¥ í‰ê°€
        final_confidence = self.training_history['confidence_scores'][-1] if self.training_history['confidence_scores'] else 0.0
        logger.info(f"Final model confidence: {final_confidence:.1%}")
        
        if final_confidence >= 0.9:
            logger.info("ğŸ‰ SUCCESS: Achieved 90%+ confidence!")
        else:
            logger.info(f"Target not reached. Current: {final_confidence:.1%}, Target: 90%")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ Enhanced Movie Scent AI - High Confidence Training Started")
    logger.info("=" * 80)
    
    trainer = EnhancedMovieScentTrainer()
    trainer.run_enhanced_training_pipeline()
    
    logger.info("âœ… Enhanced training completed!")

if __name__ == "__main__":
    main()