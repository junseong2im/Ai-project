#!/usr/bin/env python3
"""
ì˜í™” ì¥ë©´ â†’ í–¥ë£Œ ì¡°í•© ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ê¸°
10ë§Œê°œ ë°ì´í„°ì…‹ìœ¼ë¡œ ì •í™•í•œ ì›ë£Œ ì¡°í•© í•™ìŠµ
"""

import sys
import json
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Any
import logging
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import joblib

# PyTorch ì„í¬íŠ¸
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F

# ìƒìœ„ ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MovieScentDataset(Dataset):
    """ì˜í™” ì¥ë©´-í–¥ë£Œ ë°ì´í„°ì…‹"""
    
    def __init__(self, features: np.ndarray, targets: Dict[str, np.ndarray]):
        self.features = torch.FloatTensor(features)
        self.targets = {key: torch.FloatTensor(val) for key, val in targets.items()}
    
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        return {
            'features': self.features[idx],
            'targets': {key: val[idx] for key, val in self.targets.items()}
        }

class MovieScentNeuralNetwork(nn.Module):
    """ì˜í™” ì¥ë©´ ê¸°ë°˜ í–¥ë£Œ ì¶”ì²œ ì‹ ê²½ë§"""
    
    def __init__(self, input_dim: int, material_count: int, genre_count: int, emotion_count: int):
        super().__init__()
        
        self.input_dim = input_dim
        self.material_count = material_count
        self.genre_count = genre_count
        self.emotion_count = emotion_count
        
        # ê³µí†µ íŠ¹ì„± ì¶”ì¶œì¸µ
        self.feature_extractor = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.3),
            
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.2),
            
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.1)
        )
        
        # ë‹¤ì¤‘ ì¶œë ¥ í—¤ë“œë“¤
        # 1. ì›ë£Œ ë†ë„ ì˜ˆì¸¡ (íšŒê·€)
        self.material_head = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, material_count),
            nn.Sigmoid()  # 0-1 ì‚¬ì´ ë†ë„
        )
        
        # 2. íœ˜ë°œì„± ë ˆë²¨ ì˜ˆì¸¡ (ë¶„ë¥˜)
        self.volatility_head = nn.Sequential(
            nn.Linear(128, 32),
            nn.ReLU(),
            nn.Linear(32, 3)  # high, medium, low
        )
        
        # 3. ì§€ì†ì‹œê°„ ì˜ˆì¸¡ (íšŒê·€)
        self.duration_head = nn.Sequential(
            nn.Linear(128, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.ReLU()  # ì–‘ìˆ˜ ì‹œê°„
        )
        
        # 4. ê°ì • ë¶„ë¥˜
        self.emotion_head = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, emotion_count),
            nn.Sigmoid()  # ë‹¤ì¤‘ ê°ì • ê°€ëŠ¥
        )
    
    def forward(self, x):
        features = self.feature_extractor(x)
        
        return {
            'materials': self.material_head(features),
            'volatility': self.volatility_head(features),
            'duration': self.duration_head(features),
            'emotions': self.emotion_head(features)
        }

class MovieScentTrainer:
    """ì˜í™” í–¥ë£Œ ëª¨ë¸ í›ˆë ¨ê¸°"""
    
    def __init__(self, data_path: str = "generated_recipes/all_movie_recipes.json"):
        self.data_path = Path(data_path)
        self.model_save_dir = Path("models/movie_scent_models")
        self.model_save_dir.mkdir(parents=True, exist_ok=True)
        
        # ì „ì²˜ë¦¬ ë„êµ¬ë“¤
        self.feature_scaler = StandardScaler()
        self.label_encoders = {}
        self.material_vocab = {}
        self.emotion_vocab = {}
        
        # ëª¨ë¸ê³¼ ë°ì´í„°
        self.model = None
        self.train_loader = None
        self.val_loader = None
        
    def load_and_preprocess_data(self) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        logger.info(f"Loading data from {self.data_path}")
        
        with open(self.data_path, 'r', encoding='utf-8') as f:
            recipes = json.load(f)
        
        logger.info(f"Loaded {len(recipes):,} recipes")
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ì¶”ì¶œ
        features = []
        material_targets = []
        volatility_targets = []
        duration_targets = []
        emotion_targets = []
        
        # ì¬ë£Œ ì–´íœ˜ì§‘ êµ¬ì¶•
        all_materials = set()
        all_emotions = set()
        
        for recipe in recipes:
            # ëª¨ë“  ì¬ë£Œì™€ ê°ì • ìˆ˜ì§‘
            for note_type in ['top_notes', 'middle_notes', 'base_notes']:
                for note in recipe['fragrance_notes'][note_type]:
                    all_materials.add(note['name'])
            all_emotions.update(recipe['detected_emotions'])
        
        self.material_vocab = {material: idx for idx, material in enumerate(sorted(all_materials))}
        self.emotion_vocab = {emotion: idx for idx, emotion in enumerate(sorted(all_emotions))}
        
        logger.info(f"Material vocabulary size: {len(self.material_vocab)}")
        logger.info(f"Emotion vocabulary size: {len(self.emotion_vocab)}")
        
        # ê° ë ˆì‹œí”¼ ì²˜ë¦¬
        for recipe in recipes:
            # 1. íŠ¹ì„± ë²¡í„° ìƒì„± (ì¥ë©´ ì„¤ëª… ê¸°ë°˜)
            scene_features = self._extract_scene_features(recipe)
            features.append(scene_features)
            
            # 2. ì¬ë£Œ ë†ë„ ë²¡í„°
            material_vector = self._extract_material_concentrations(recipe)
            material_targets.append(material_vector)
            
            # 3. íœ˜ë°œì„± ë ˆë²¨
            volatility_level = self._encode_volatility(recipe['volatility_level'])
            volatility_targets.append(volatility_level)
            
            # 4. ì§€ì†ì‹œê°„ (ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜)
            duration = self._extract_duration_seconds(recipe['duration_estimate'])
            duration_targets.append(duration)
            
            # 5. ê°ì • ë²¡í„°
            emotion_vector = self._encode_emotions(recipe['detected_emotions'])
            emotion_targets.append(emotion_vector)
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        X = np.array(features)
        y = {
            'materials': np.array(material_targets),
            'volatility': np.array(volatility_targets),
            'duration': np.array(duration_targets).reshape(-1, 1),
            'emotions': np.array(emotion_targets)
        }
        
        logger.info(f"Feature shape: {X.shape}")
        logger.info(f"Material target shape: {y['materials'].shape}")
        logger.info(f"Volatility target shape: {y['volatility'].shape}")
        logger.info(f"Duration target shape: {y['duration'].shape}")
        logger.info(f"Emotion target shape: {y['emotions'].shape}")
        
        # íŠ¹ì„± ì •ê·œí™”
        X = self.feature_scaler.fit_transform(X)
        
        return X, y
    
    def _extract_scene_features(self, recipe: Dict) -> List[float]:
        """ì¥ë©´ìœ¼ë¡œë¶€í„° íŠ¹ì„± ë²¡í„° ì¶”ì¶œ"""
        scene_desc = recipe['scene_description']
        metadata = recipe['metadata']
        
        features = []
        
        # 1. ì¥ë¥´ ì›-í•« ì¸ì½”ë”© (7ê°œ ì¥ë¥´)
        genres = ['action', 'romantic', 'horror', 'drama', 'thriller', 'comedy', 'sci_fi']
        genre_vector = [1.0 if metadata['genre'] == genre else 0.0 for genre in genres]
        features.extend(genre_vector)
        
        # 2. í…ìŠ¤íŠ¸ íŠ¹ì„± (í‚¤ì›Œë“œ ê¸°ë°˜)
        text_features = self._extract_text_features(scene_desc)
        features.extend(text_features)
        
        # 3. ë©”íƒ€ë°ì´í„° íŠ¹ì„±
        features.append(float(metadata.get('recipe_id', 0)) / 100000.0)  # ì •ê·œí™”
        
        return features
    
    def _extract_text_features(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì„± ì¶”ì¶œ"""
        text_lower = text.lower()
        
        # ê°ì • í‚¤ì›Œë“œ
        emotion_keywords = {
            'action': ['explosion', 'chase', 'fight', 'battle', 'war', 'gun', 'car'],
            'romantic': ['love', 'kiss', 'couple', 'romantic', 'heart', 'tender'],
            'scary': ['dark', 'scary', 'horror', 'fear', 'blood', 'nightmare'],
            'peaceful': ['calm', 'quiet', 'peaceful', 'serene', 'meditation'],
            'nature': ['forest', 'ocean', 'mountain', 'garden', 'flower', 'tree'],
            'urban': ['city', 'street', 'building', 'office', 'hotel', 'club'],
            'temporal': ['morning', 'night', 'sunset', 'dawn', 'evening', 'midnight']
        }
        
        features = []
        for category, keywords in emotion_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower) / len(keywords)
            features.append(score)
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ íŠ¹ì„±
        features.append(len(text.split()) / 20.0)  # ì •ê·œí™”ëœ ë‹¨ì–´ ìˆ˜
        
        return features
    
    def _extract_material_concentrations(self, recipe: Dict) -> List[float]:
        """ì›ë£Œë³„ ë†ë„ ë²¡í„° ì¶”ì¶œ"""
        concentrations = [0.0] * len(self.material_vocab)
        
        for note_type in ['top_notes', 'middle_notes', 'base_notes']:
            for note in recipe['fragrance_notes'][note_type]:
                material_name = note['name']
                if material_name in self.material_vocab:
                    idx = self.material_vocab[material_name]
                    concentrations[idx] = float(note['concentration_percent']) / 100.0  # 0-1 ì •ê·œí™”
        
        return concentrations
    
    def _encode_volatility(self, volatility_level: str) -> int:
        """íœ˜ë°œì„± ë ˆë²¨ ì¸ì½”ë”©"""
        volatility_map = {
            'low_volatility': 0,
            'medium_volatility': 1,
            'high_volatility': 2
        }
        return volatility_map.get(volatility_level, 1)
    
    def _extract_duration_seconds(self, duration_str: str) -> float:
        """ì§€ì†ì‹œê°„ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜"""
        if '10-30ì´ˆ' in duration_str:
            return 20.0
        elif '1-2ë¶„' in duration_str:
            return 90.0
        elif '2-5ë¶„' in duration_str:
            return 210.0
        elif '5-10ë¶„' in duration_str:
            return 450.0
        else:
            return 120.0  # ê¸°ë³¸ê°’
    
    def _encode_emotions(self, emotions: List[str]) -> List[float]:
        """ê°ì • ë‹¤ì¤‘ ë¼ë²¨ ì¸ì½”ë”©"""
        emotion_vector = [0.0] * len(self.emotion_vocab)
        for emotion in emotions:
            if emotion in self.emotion_vocab:
                idx = self.emotion_vocab[emotion]
                emotion_vector[idx] = 1.0
        return emotion_vector
    
    def create_data_loaders(self, X: np.ndarray, y: Dict[str, np.ndarray], 
                           batch_size: int = 64, test_size: float = 0.2):
        """ë°ì´í„° ë¡œë” ìƒì„±"""
        # í›ˆë ¨/ê²€ì¦ ë¶„í• 
        indices = np.arange(len(X))
        train_idx, val_idx = train_test_split(indices, test_size=test_size, random_state=42)
        
        X_train, X_val = X[train_idx], X[val_idx]
        y_train = {key: val[train_idx] for key, val in y.items()}
        y_val = {key: val[val_idx] for key, val in y.items()}
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = MovieScentDataset(X_train, y_train)
        val_dataset = MovieScentDataset(X_val, y_val)
        
        # ë°ì´í„° ë¡œë” ìƒì„±
        self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        self.val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        
        logger.info(f"Train samples: {len(train_dataset)}")
        logger.info(f"Validation samples: {len(val_dataset)}")
    
    def create_model(self, input_dim: int):
        """ëª¨ë¸ ìƒì„±"""
        material_count = len(self.material_vocab)
        emotion_count = len(self.emotion_vocab)
        
        self.model = MovieScentNeuralNetwork(
            input_dim=input_dim,
            material_count=material_count,
            genre_count=7,
            emotion_count=emotion_count
        )
        
        logger.info(f"Model created with input_dim={input_dim}")
        logger.info(f"Material count: {material_count}")
        logger.info(f"Emotion count: {emotion_count}")
    
    def train_model(self, epochs: int = 100, lr: float = 0.001):
        """ëª¨ë¸ í›ˆë ¨"""
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"Using device: {device}")
        
        self.model.to(device)
        
        # ì†ì‹¤ í•¨ìˆ˜ë“¤
        material_criterion = nn.MSELoss()  # ë†ë„ íšŒê·€
        volatility_criterion = nn.CrossEntropyLoss()  # íœ˜ë°œì„± ë¶„ë¥˜
        duration_criterion = nn.MSELoss()  # ì§€ì†ì‹œê°„ íšŒê·€
        emotion_criterion = nn.BCELoss()  # ê°ì • ë‹¤ì¤‘ ë¼ë²¨
        
        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-4)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)
        
        best_val_loss = float('inf')
        
        for epoch in range(epochs):
            # í›ˆë ¨
            self.model.train()
            train_losses = []
            
            for batch in self.train_loader:
                features = batch['features'].to(device)
                targets = {key: val.to(device) for key, val in batch['targets'].items()}
                
                optimizer.zero_grad()
                
                outputs = self.model(features)
                
                # ê° ì†ì‹¤ ê³„ì‚°
                material_loss = material_criterion(outputs['materials'], targets['materials'])
                volatility_loss = volatility_criterion(outputs['volatility'], targets['volatility'].long())
                duration_loss = duration_criterion(outputs['duration'], targets['duration'])
                emotion_loss = emotion_criterion(outputs['emotions'], targets['emotions'])
                
                # ì´ ì†ì‹¤ (ê°€ì¤‘ í•©)
                total_loss = (
                    2.0 * material_loss +    # ì›ë£Œ ì¡°í•©ì´ ê°€ì¥ ì¤‘ìš”
                    1.0 * volatility_loss +
                    0.5 * duration_loss +
                    1.0 * emotion_loss
                )
                
                total_loss.backward()
                optimizer.step()
                
                train_losses.append(total_loss.item())
            
            # ê²€ì¦
            self.model.eval()
            val_losses = []
            
            with torch.no_grad():
                for batch in self.val_loader:
                    features = batch['features'].to(device)
                    targets = {key: val.to(device) for key, val in batch['targets'].items()}
                    
                    outputs = self.model(features)
                    
                    material_loss = material_criterion(outputs['materials'], targets['materials'])
                    volatility_loss = volatility_criterion(outputs['volatility'], targets['volatility'].long())
                    duration_loss = duration_criterion(outputs['duration'], targets['duration'])
                    emotion_loss = emotion_criterion(outputs['emotions'], targets['emotions'])
                    
                    total_loss = (
                        2.0 * material_loss +
                        1.0 * volatility_loss +
                        0.5 * duration_loss +
                        1.0 * emotion_loss
                    )
                    
                    val_losses.append(total_loss.item())
            
            avg_train_loss = np.mean(train_losses)
            avg_val_loss = np.mean(val_losses)
            
            scheduler.step(avg_val_loss)
            
            if epoch % 10 == 0:
                logger.info(f"Epoch {epoch:3d}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}")
            
            # ìµœê³  ëª¨ë¸ ì €ì¥
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                self.save_model_and_preprocessors()
        
        logger.info(f"Training completed! Best validation loss: {best_val_loss:.4f}")
    
    def save_model_and_preprocessors(self):
        """ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸° ì €ì¥"""
        # ëª¨ë¸ ì €ì¥
        model_path = self.model_save_dir / "movie_scent_model.pth"
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'model_config': {
                'input_dim': self.model.input_dim,
                'material_count': self.model.material_count,
                'genre_count': self.model.genre_count,
                'emotion_count': self.model.emotion_count
            }
        }, model_path)
        
        # ì „ì²˜ë¦¬ê¸°ë“¤ ì €ì¥
        preprocessor_path = self.model_save_dir / "preprocessors.pkl"
        joblib.dump({
            'feature_scaler': self.feature_scaler,
            'material_vocab': self.material_vocab,
            'emotion_vocab': self.emotion_vocab,
            'label_encoders': self.label_encoders
        }, preprocessor_path)
        
        logger.info(f"Model saved to: {model_path}")
        logger.info(f"Preprocessors saved to: {preprocessor_path}")
    
    def run_full_training_pipeline(self):
        """ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("Starting full training pipeline...")
        
        # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        X, y = self.load_and_preprocess_data()
        
        # 2. ë°ì´í„° ë¡œë” ìƒì„±
        self.create_data_loaders(X, y)
        
        # 3. ëª¨ë¸ ìƒì„±
        self.create_model(input_dim=X.shape[1])
        
        # 4. ëª¨ë¸ í›ˆë ¨
        self.train_model(epochs=200, lr=0.001)
        
        logger.info("Training pipeline completed successfully!")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸ¬ Movie Scent AI - Deep Learning Training Started")
    logger.info("=" * 60)
    
    trainer = MovieScentTrainer()
    trainer.run_full_training_pipeline()
    
    logger.info("âœ… Training completed! Model ready for movie scene fragrance prediction.")

if __name__ == "__main__":
    main()