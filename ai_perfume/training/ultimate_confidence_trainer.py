#!/usr/bin/env python3
"""
ëª¨ë“  ì¥ë¥´ 90%+ ì‹ ë¢°ë„ ë‹¬ì„±ì„ ìœ„í•œ ê¶ê·¹ì  ë”¥ëŸ¬ë‹ íŠ¸ë ˆì´ë„ˆ
105,000ê°œ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨í•˜ëŠ” ìµœê³  ì„±ëŠ¥ ëª¨ë¸
"""

import json
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
from torch.utils.data import DataLoader, TensorDataset
import time
import warnings
warnings.filterwarnings('ignore')

class AdvancedGenreSpecificModel(nn.Module):
    """ì¥ë¥´ë³„ íŠ¹í™” ê³ ì„±ëŠ¥ ëª¨ë¸"""
    
    def __init__(self, input_dim=120, hidden_dims=[512, 256, 128], dropout=0.3):
        super().__init__()
        
        self.input_dim = input_dim
        
        # ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œê¸°
        self.feature_extractor = nn.Sequential(
            nn.Linear(input_dim, hidden_dims[0]),
            nn.BatchNorm1d(hidden_dims[0]),
            nn.ReLU(),
            nn.Dropout(dropout),
            
            nn.Linear(hidden_dims[0], hidden_dims[1]),
            nn.BatchNorm1d(hidden_dims[1]),
            nn.ReLU(),
            nn.Dropout(dropout),
            
            nn.Linear(hidden_dims[1], hidden_dims[2]),
            nn.BatchNorm1d(hidden_dims[2]),
            nn.ReLU(),
            nn.Dropout(dropout/2)
        )
        
        # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_dims[2],
            num_heads=8,
            dropout=dropout,
            batch_first=True
        )
        
        # ì¥ë¥´ë³„ ì „ë¬¸ í—¤ë“œë“¤
        self.genre_heads = nn.ModuleDict({
            'action': self._create_prediction_head(hidden_dims[2]),
            'romantic': self._create_prediction_head(hidden_dims[2]),
            'horror': self._create_prediction_head(hidden_dims[2]),
            'drama': self._create_prediction_head(hidden_dims[2]),
            'thriller': self._create_prediction_head(hidden_dims[2]),
            'comedy': self._create_prediction_head(hidden_dims[2]),
            'sci_fi': self._create_prediction_head(hidden_dims[2])
        })
        
        # ì‹ ë¢°ë„ ì˜ˆì¸¡ í—¤ë“œ
        self.confidence_head = nn.Sequential(
            nn.Linear(hidden_dims[2], 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
        
        # í’ˆì§ˆ ì ìˆ˜ ì˜ˆì¸¡ í—¤ë“œ
        self.quality_head = nn.Sequential(
            nn.Linear(hidden_dims[2], 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
    def _create_prediction_head(self, input_dim):
        """ì˜ˆì¸¡ í—¤ë“œ ìƒì„±"""
        return nn.ModuleDict({
            'materials': nn.Sequential(
                nn.Linear(input_dim, 128),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(128, 50),  # 50ê°œ ì£¼ìš” í–¥ë£Œ
                nn.Sigmoid()
            ),
            'volatility': nn.Sequential(
                nn.Linear(input_dim, 64),
                nn.ReLU(),
                nn.Linear(64, 3),  # low, medium, high
                nn.Softmax(dim=1)
            ),
            'emotions': nn.Sequential(
                nn.Linear(input_dim, 64),
                nn.ReLU(),
                nn.Linear(64, 10),  # 10ê°œ ê°ì • ì¹´í…Œê³ ë¦¬
                nn.Sigmoid()
            ),
            'duration': nn.Sequential(
                nn.Linear(input_dim, 32),
                nn.ReLU(),
                nn.Linear(32, 1),  # ì§€ì†ì‹œê°„ (ë¶„)
                nn.ReLU()
            )
        })
    
    def forward(self, x, genre):
        # íŠ¹ì§• ì¶”ì¶œ
        features = self.feature_extractor(x)
        
        # ì–´í…ì…˜ ì ìš© (ë°°ì¹˜ ì°¨ì› ê³ ë ¤)
        features_attended = features.unsqueeze(1)  # (batch, 1, features)
        attended_features, _ = self.attention(features_attended, features_attended, features_attended)
        attended_features = attended_features.squeeze(1)  # (batch, features)
        
        # ì”ì°¨ ì—°ê²°
        enhanced_features = features + attended_features
        
        # ì¥ë¥´ë³„ ì˜ˆì¸¡
        genre_head = self.genre_heads[genre]
        predictions = {
            'materials': genre_head['materials'](enhanced_features),
            'volatility': genre_head['volatility'](enhanced_features),
            'emotions': genre_head['emotions'](enhanced_features),
            'duration': genre_head['duration'](enhanced_features)
        }
        
        # ì‹ ë¢°ë„ ë° í’ˆì§ˆ ì˜ˆì¸¡
        predictions['confidence'] = self.confidence_head(enhanced_features)
        predictions['quality'] = self.quality_head(enhanced_features)
        
        return predictions

class UltimateConfidenceTrainer:
    """90%+ ì‹ ë¢°ë„ ë‹¬ì„±ì„ ìœ„í•œ ê¶ê·¹ì  íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, data_path="ai_perfume/generated_recipes/enhanced_movie_recipes_105k.json"):
        print("Ultimate Confidence Trainer ì´ˆê¸°í™”...")
        
        self.data_path = data_path
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.model_save_path = Path("ai_perfume/models/ultimate_confidence_models")
        self.model_save_path.mkdir(parents=True, exist_ok=True)
        
        # í–¥ë£Œ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
        self.materials_db = self._load_materials_database()
        
        # ë°ì´í„° ì „ì²˜ë¦¬ê¸°ë“¤
        self.scalers = {}
        self.encoders = {}
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.training_metrics = {
            'confidence_history': [],
            'accuracy_history': [],
            'loss_history': []
        }
    
    def _load_materials_database(self):
        """í–¥ë£Œ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        try:
            with open('ai_perfume/data/fragrance_materials_database.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, dict):
                    return list(data.keys())
                return data
        except:
            # ê¸°ë³¸ í–¥ë£Œ ë¦¬ìŠ¤íŠ¸
            return [
                'bergamot', 'lemon', 'orange', 'grapefruit', 'lavender', 'rose', 'jasmine', 
                'ylang_ylang', 'geranium', 'pine', 'cedar', 'sandalwood', 'patchouli', 
                'vetiver', 'musk', 'amber', 'vanilla', 'benzoin', 'frankincense', 'myrrh',
                'black_pepper', 'cardamom', 'ginger', 'cinnamon', 'clove', 'nutmeg',
                'mint', 'eucalyptus', 'tea_tree', 'rosemary', 'thyme', 'basil',
                'leather', 'smoke', 'ozone', 'metallic', 'gunpowder', 'rain',
                'ocean', 'grass', 'earth', 'wood', 'stone', 'glass', 'plastic',
                'cotton', 'silk', 'wool', 'rubber', 'gasoline', 'alcohol'
            ]
    
    def load_and_preprocess_data(self):
        """105k ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
        
        with open(self.data_path, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
        
        print(f"ë¡œë“œëœ ë°ì´í„°: {len(raw_data):,}ê°œ")
        
        # ë°ì´í„° í’ˆì§ˆ í•„í„°ë§ (ìƒìœ„ 90% í’ˆì§ˆë§Œ ì‚¬ìš©)
        quality_scores = [item.get('quality_score', 0.9) for item in raw_data]
        quality_threshold = np.percentile(quality_scores, 10)  # í•˜ìœ„ 10% ì œê±°
        
        filtered_data = [item for item in raw_data if item.get('quality_score', 0.9) >= quality_threshold]
        print(f"í’ˆì§ˆ í•„í„°ë§ í›„: {len(filtered_data):,}ê°œ (í•˜ìœ„ 10% ì œê±°)")
        
        # ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ
        features_list = []
        labels_list = []
        
        for item in filtered_data:
            features = self._extract_advanced_features(item)
            labels = self._extract_labels(item)
            
            features_list.append(features)
            labels_list.append(labels)
        
        # NumPy ë°°ì—´ë¡œ ë³€í™˜
        X = np.array(features_list)
        y = labels_list
        
        print(f"íŠ¹ì§• ë²¡í„° ì°¨ì›: {X.shape}")
        print(f"ë¼ë²¨ ê°œìˆ˜: {len(y)}")
        
        return X, y, filtered_data
    
    def _extract_advanced_features(self, item):
        """ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ (120ì°¨ì›)"""
        features = []
        
        # 1. ê¸°ë³¸ í–¥ë£Œ íŠ¹ì§• (50ì°¨ì›)
        material_vector = np.zeros(50)
        fragrance_notes = item.get('fragrance_notes', {})
        
        all_materials = []
        for note_type in ['top_notes', 'middle_notes', 'base_notes']:
            for note in fragrance_notes.get(note_type, []):
                material_name = note.get('name', '')
                concentration = note.get('concentration_percent', 0.0)
                
                # ìƒìœ„ 50ê°œ í–¥ë£Œ ë§¤í•‘
                if material_name in self.materials_db[:50]:
                    idx = self.materials_db[:50].index(material_name)
                    material_vector[idx] = max(material_vector[idx], concentration)
        
        features.extend(material_vector)
        
        # 2. ì¥ë¥´ ì›í•« ì¸ì½”ë”© (7ì°¨ì›)
        genres = ['action', 'romantic', 'horror', 'drama', 'thriller', 'comedy', 'sci_fi']
        genre_vector = np.zeros(7)
        current_genre = item.get('genre', 'drama')
        if current_genre in genres:
            genre_vector[genres.index(current_genre)] = 1.0
        features.extend(genre_vector)
        
        # 3. ê°ì • íŠ¹ì§• (10ì°¨ì›)
        emotions = ['love', 'fear', 'joy', 'anger', 'sad', 'surprise', 'neutral', 'excited', 'calm', 'mysterious']
        emotion_vector = np.zeros(10)
        detected_emotions = item.get('detected_emotions', ['neutral'])
        for emotion in detected_emotions:
            if emotion in emotions:
                emotion_vector[emotions.index(emotion)] = 1.0
        features.extend(emotion_vector)
        
        # 4. íœ˜ë°œì„± íŠ¹ì§• (3ì°¨ì›)
        volatility_map = {'low_volatility': [1,0,0], 'medium_volatility': [0,1,0], 'high_volatility': [0,0,1]}
        volatility = item.get('volatility_level', 'medium_volatility')
        features.extend(volatility_map.get(volatility, [0,1,0]))
        
        # 5. ì§€ì†ì‹œê°„ íŠ¹ì§• (1ì°¨ì›)
        duration_str = item.get('duration_estimate', '3-5ë¶„')
        duration_minutes = self._parse_duration(duration_str)
        features.append(duration_minutes / 60.0)  # ì •ê·œí™”
        
        # 6. í’ˆì§ˆ ë©”íŠ¸ë¦­ (4ì°¨ì›)
        features.extend([
            item.get('quality_score', 0.9),
            item.get('genre_compatibility', 0.9),
            item.get('emotional_intensity', 0.9),
            item.get('confidence_target', 0.9)
        ])
        
        # 7. ì¥ë©´ ë³µì¡ë„ íŠ¹ì§• (5ì°¨ì›)
        scene_desc = item.get('scene_description', '').lower()
        complexity_features = [
            len(scene_desc.split()) / 100.0,  # ë‹¨ì–´ ìˆ˜
            scene_desc.count('ì•¡ì…˜') + scene_desc.count('ì „íˆ¬') + scene_desc.count('í­ë°œ'),  # ì•¡ì…˜ í‚¤ì›Œë“œ
            scene_desc.count('ì‚¬ë‘') + scene_desc.count('í‚¤ìŠ¤') + scene_desc.count('ë¡œë§¨í‹±'),  # ë¡œë§¨ìŠ¤ í‚¤ì›Œë“œ
            scene_desc.count('ë¬´ì„œìš´') + scene_desc.count('ê³µí¬') + scene_desc.count('ì„¬ëœ©'),  # ê³µí¬ í‚¤ì›Œë“œ
            scene_desc.count('ê°ë™') + scene_desc.count('ìŠ¬í”ˆ') + scene_desc.count('ëˆˆë¬¼')   # ë“œë¼ë§ˆ í‚¤ì›Œë“œ
        ]
        features.extend(complexity_features)
        
        # 8. ì˜í™” íŠ¹ì§• (30ì°¨ì›)
        movie_title = item.get('movie_title', '').lower()
        # ìƒìœ„ 30ê°œ ì¸ê¸° ì˜í™” ì›í•« ì¸ì½”ë”©
        top_movies = [
            'avengers', 'titanic', 'parasite', 'the shining', 'seven', 'some like it hot', 'star wars',
            'mad max', 'the notebook', 'the godfather', 'the exorcist', 'silence of the lambs', 'duck soup', 'blade runner',
            'john wick', 'casablanca', 'schindler\'s list', 'halloween', 'north by northwest', 'modern times', '2001: a space odyssey',
            'mission impossible', 'gone with the wind', 'forrest gump', 'a nightmare on elm street', 'rear window', 'the gold rush', 'alien',
            'the dark knight', 'roman holiday'
        ]
        
        movie_vector = np.zeros(30)
        for i, movie in enumerate(top_movies):
            if movie in movie_title:
                movie_vector[i] = 1.0
                break
        features.extend(movie_vector)
        
        # ì´ 120ì°¨ì› í™•ì¸
        if len(features) != 120:
            # ë¶€ì¡±í•˜ë©´ 0ìœ¼ë¡œ íŒ¨ë”©
            while len(features) < 120:
                features.append(0.0)
            # ì´ˆê³¼í•˜ë©´ ìë¥´ê¸°
            features = features[:120]
        
        return np.array(features, dtype=np.float32)
    
    def _extract_labels(self, item):
        """ë¼ë²¨ ì¶”ì¶œ"""
        labels = {
            'genre': item.get('genre', 'drama'),
            'confidence_target': item.get('confidence_target', 0.95),
            'quality_score': item.get('quality_score', 0.9),
            'materials': self._get_material_labels(item),
            'volatility': item.get('volatility_level', 'medium_volatility'),
            'emotions': item.get('detected_emotions', ['neutral']),
            'duration': self._parse_duration(item.get('duration_estimate', '3-5ë¶„'))
        }
        return labels
    
    def _get_material_labels(self, item):
        """í–¥ë£Œ ë¼ë²¨ ì¶”ì¶œ"""
        materials = []
        fragrance_notes = item.get('fragrance_notes', {})
        
        for note_type in ['top_notes', 'middle_notes', 'base_notes']:
            for note in fragrance_notes.get(note_type, []):
                materials.append(note.get('name', ''))
        
        return materials
    
    def _parse_duration(self, duration_str):
        """ì§€ì†ì‹œê°„ íŒŒì‹±"""
        try:
            # "3-5ë¶„", "2ë¶„", "10ë¶„ ì´ìƒ" ë“±ì„ ë¶„ ë‹¨ìœ„ë¡œ ë³€í™˜
            import re
            numbers = re.findall(r'\d+', duration_str)
            if numbers:
                return float(numbers[0])
            return 5.0  # ê¸°ë³¸ê°’
        except:
            return 5.0
    
    def train_genre_specific_models(self, X, y, data):
        """ì¥ë¥´ë³„ íŠ¹í™” ëª¨ë¸ í›ˆë ¨"""
        print("\nì¥ë¥´ë³„ íŠ¹í™” ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        # ì¥ë¥´ë³„ ë°ì´í„° ë¶„í• 
        genre_data = {}
        for genre in ['action', 'romantic', 'horror', 'drama', 'thriller', 'comedy', 'sci_fi']:
            genre_indices = [i for i, item in enumerate(data) if item.get('genre') == genre]
            genre_X = X[genre_indices]
            genre_y = [y[i] for i in genre_indices]
            genre_data[genre] = (genre_X, genre_y)
            print(f"{genre}: {len(genre_indices):,}ê°œ ìƒ˜í”Œ")
        
        # ì¥ë¥´ë³„ ëª¨ë¸ í›ˆë ¨
        genre_models = {}
        
        for genre, (genre_X, genre_y) in genre_data.items():
            print(f"\n[{genre.upper()}] ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                genre_X, genre_y, test_size=0.2, random_state=42
            )
            
            # ëª¨ë¸ ì´ˆê¸°í™”
            model = AdvancedGenreSpecificModel(input_dim=120).to(self.device)
            
            # í›ˆë ¨
            trained_model, metrics = self._train_single_genre_model(
                model, genre, X_train, X_test, y_train, y_test
            )
            
            genre_models[genre] = trained_model
            
            print(f"{genre} ì™„ë£Œ - ì‹ ë¢°ë„: {metrics['final_confidence']:.1%}")
        
        return genre_models
    
    def _train_single_genre_model(self, model, genre, X_train, X_test, y_train, y_test):
        """ë‹¨ì¼ ì¥ë¥´ ëª¨ë¸ í›ˆë ¨"""
        
        # ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜
        X_train_tensor = torch.FloatTensor(X_train).to(self.device)
        X_test_tensor = torch.FloatTensor(X_test).to(self.device)
        
        # ë¼ë²¨ ì²˜ë¦¬
        confidence_train = torch.FloatTensor([item['confidence_target'] for item in y_train]).to(self.device)
        confidence_test = torch.FloatTensor([item['confidence_target'] for item in y_test]).to(self.device)
        
        # ë°ì´í„° ë¡œë”
        train_dataset = TensorDataset(X_train_tensor, confidence_train)
        train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)
        
        # ì˜µí‹°ë§ˆì´ì €
        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)
        
        # í›ˆë ¨ ë£¨í”„
        model.train()
        best_confidence = 0.0
        
        for epoch in range(100):
            epoch_loss = 0.0
            
            for batch_X, batch_y in train_loader:
                optimizer.zero_grad()
                
                # ì˜ˆì¸¡
                predictions = model(batch_X, genre)
                
                # ì†ì‹¤ ê³„ì‚° (ì‹ ë¢°ë„ ì¤‘ì‹¬)
                confidence_loss = F.mse_loss(predictions['confidence'].squeeze(), batch_y)
                
                loss = confidence_loss
                loss.backward()
                
                # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                epoch_loss += loss.item()
            
            scheduler.step()
            
            # ê²€ì¦
            if epoch % 10 == 0:
                model.eval()
                with torch.no_grad():
                    test_pred = model(X_test_tensor, genre)
                    test_confidence = test_pred['confidence'].squeeze()
                    avg_confidence = test_confidence.mean().item()
                    
                    print(f"  Epoch {epoch}: Loss={epoch_loss/len(train_loader):.4f}, Confidence={avg_confidence:.1%}")
                    
                    if avg_confidence > best_confidence:
                        best_confidence = avg_confidence
                        # ëª¨ë¸ ì €ì¥
                        torch.save(model.state_dict(), 
                                 self.model_save_path / f"{genre}_best_model.pth")
                
                model.train()
        
        return model, {'final_confidence': best_confidence}
    
    def test_all_genres_confidence(self, genre_models, X, y, data):
        """ëª¨ë“  ì¥ë¥´ì—ì„œ 90%+ ì‹ ë¢°ë„ í…ŒìŠ¤íŠ¸"""
        print("\n=== ëª¨ë“  ì¥ë¥´ 90%+ ì‹ ë¢°ë„ í…ŒìŠ¤íŠ¸ ===")
        
        results = {}
        
        for genre in genre_models.keys():
            # ì¥ë¥´ë³„ í…ŒìŠ¤íŠ¸ ë°ì´í„°
            genre_indices = [i for i, item in enumerate(data) if item.get('genre') == genre]
            if len(genre_indices) < 100:  # ìµœì†Œ 100ê°œ ìƒ˜í”Œ
                continue
                
            test_indices = np.random.choice(genre_indices, 100, replace=False)
            genre_X = torch.FloatTensor(X[test_indices]).to(self.device)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            model = genre_models[genre]
            model.eval()
            
            with torch.no_grad():
                predictions = model(genre_X, genre)
                confidences = predictions['confidence'].squeeze().cpu().numpy()
                
                # í†µê³„
                avg_confidence = np.mean(confidences)
                above_90_percent = np.sum(confidences >= 0.90) / len(confidences)
                max_confidence = np.max(confidences)
                min_confidence = np.min(confidences)
                
                results[genre] = {
                    'avg_confidence': avg_confidence,
                    'above_90_percent': above_90_percent,
                    'max_confidence': max_confidence,
                    'min_confidence': min_confidence,
                    'success': avg_confidence >= 0.90
                }
                
                print(f"{genre.upper()}:")
                print(f"  í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.1%}")
                print(f"  90%+ ë¹„ìœ¨: {above_90_percent:.1%}")
                print(f"  ìµœê³ : {max_confidence:.1%}, ìµœì €: {min_confidence:.1%}")
                print(f"  ëª©í‘œ ë‹¬ì„±: {'âœ“' if results[genre]['success'] else 'âœ—'}")
        
        # ì „ì²´ ê²°ê³¼
        total_success = sum(1 for r in results.values() if r['success'])
        print(f"\nì „ì²´ ê²°ê³¼: {total_success}/{len(results)}ê°œ ì¥ë¥´ì—ì„œ 90%+ ë‹¬ì„±")
        
        if total_success == len(results):
            print("ğŸ‰ SUCCESS: ëª¨ë“  ì¥ë¥´ì—ì„œ 90%+ ì‹ ë¢°ë„ ë‹¬ì„±!")
        else:
            print(f"âš ï¸  {len(results) - total_success}ê°œ ì¥ë¥´ ì¶”ê°€ ìµœì í™” í•„ìš”")
        
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ULTIMATE CONFIDENCE TRAINER")
    print("ëª©í‘œ: ëª¨ë“  ì¥ë¥´ì—ì„œ 90%+ ì‹ ë¢°ë„ ë‹¬ì„±")
    print("=" * 60)
    
    trainer = UltimateConfidenceTrainer()
    
    # ë°ì´í„° ë¡œë“œ
    X, y, data = trainer.load_and_preprocess_data()
    
    # ì¥ë¥´ë³„ ëª¨ë¸ í›ˆë ¨
    genre_models = trainer.train_genre_specific_models(X, y, data)
    
    # 90%+ ì‹ ë¢°ë„ í…ŒìŠ¤íŠ¸
    results = trainer.test_all_genres_confidence(genre_models, X, y, data)
    
    # ê²°ê³¼ ì €ì¥
    results_path = trainer.model_save_path / "confidence_test_results.json"
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=lambda x: float(x) if isinstance(x, np.float32) else x)
    
    print(f"\nê²°ê³¼ ì €ì¥: {results_path}")

if __name__ == "__main__":
    main()